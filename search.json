[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Embedded Systems Design",
    "section": "",
    "text": "Preface",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Embedded Systems Design",
    "section": "Welcome",
    "text": "Welcome\nWelcome to the “System Design with Silicon Lab EFR32XG24 BLE Microcontroller”. This book is designed to guide you through the process of programming, building applications, and integrating machine learning with the EFR32XG24 BLE Microcontroller. Whether you’re an engineering student or a seasoned professional, this book offers hands-on examples to make advanced concepts accessible.\nYou’ll learn how to: - Program the EFR32XG24 microcontroller using C. - Design and implement embedded systems applications. - Apply machine learning techniques to solve real-world problems. - Explore gesture recognition, anomaly detection, and audio-based ML solutions.\nThe book balances theory with practice, empowering readers to develop embedded systems that are robust, efficient, and intelligent.\nIf you’re interested in broader programming concepts or other machine learning platforms, we encourage you to explore additional resources and apply your learning across domains.\n\n\n\n\n\n\nThis book was originally developed as part of the EE260 and EE513 courses at Clarkson University. The Quarto-based version serves as an example of modern technical publishing and open access education.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Embedded Systems Design",
    "section": "License",
    "text": "License\nThis book is free to use under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. You are welcome to share, adapt, and use the material for educational purposes, as long as proper attribution is given and no commercial use is made.\nIf you’d like to support the project or contribute, you can report issues or submit pull requests at github.com/clarkson-edge/ee513_book. Thank you for helping improve this resource for the community.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "contents/core/1_introduction.html",
    "href": "contents/core/1_introduction.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 Overview\nEmbedded systems are specialized computing systems that are designed to perform dedicated functions or tasks within a larger mechanical or electrical system. Unlike general-purpose computers, embedded systems are optimized for specific applications, balancing constraints such as power consumption, real-time performance, and cost efficiency. They are integral to a wide range of applications, including consumer electronics, automotive systems, medical devices, industrial automation, and smart home technologies.\nAt the core of most embedded systems lies a microcontroller, a compact integrated circuit that combines a processor, memory, and input/output peripherals on a single chip. Microcontrollers are the brain of embedded systems, executing pre-programmed instructions to manage sensors, actuators, and communication modules. Their efficiency, reliability, and low power consumption make them ideal for embedded applications.\nIn recent years, the demand for wireless communication in embedded systems has surged, driven by the growth of the Internet of Things (IoT). Among the various wireless protocols, Bluetooth Low Energy (BLE) has emerged as a key technology for low-power, short-range communication. BLE enables devices to transmit small amounts of data with minimal energy consumption, making it ideal for battery-operated applications such as fitness trackers, smart home devices, and health monitoring systems.\nThe Silicon Labs EFR32XG24 series is one of the most advanced BLE microcontrollers available in Q4 of 2024. Built on the ARM Cortex-M33 core, it offers a powerful blend of performance, energy efficiency, and wireless connectivity. It is equipped with a robust BLE stack, extensive peripherals, and advanced security features, making it a preferred choice for designing sophisticated embedded systems.\nThis textbook, System Design with Silicon Lab EFR32XG24 BLE Microcontroller, is intended to provide a guide for students and engineers to understand and design embedded systems using the EFR32xG24 Dev Kit. The book covers both theoretical concepts and hands-on practical implementations, ensuring readers gain a deep understanding of embedded system design and BLE communication protocols.\nThroughout this book, readers will learn:",
    "crumbs": [
      "Embedded Systems Design",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "contents/core/1_introduction.html#overview",
    "href": "contents/core/1_introduction.html#overview",
    "title": "1  Introduction",
    "section": "",
    "text": "The fundamentals of embedded systems and microcontroller architecture.\nKey features and capabilities of the EFR32XG24 BLE microcontroller.\nPractical techniques for programming and debugging embedded systems.\nBLE communication protocols and integration with IoT applications.\nReal-world case studies and projects demonstrating system design principles.",
    "crumbs": [
      "Embedded Systems Design",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "contents/core/1_introduction.html#real-world-applications-of-embedded-systems",
    "href": "contents/core/1_introduction.html#real-world-applications-of-embedded-systems",
    "title": "1  Introduction",
    "section": "1.2 Real-World Applications of Embedded Systems",
    "text": "1.2 Real-World Applications of Embedded Systems\nEmbedded systems are deeply integrated into modern life, serving as the backbone for countless devices and technologies. They are designed to execute dedicated functions efficiently while operating under constraints such as power consumption, memory limitations, and cost. Examples of embedded systems can be observed in both everyday objects and complex industrial applications, showcasing their versatility and importance in modern engineering.\nOne prominent example is the automotive industry, where embedded systems play a critical role in ensuring safety, efficiency, and advanced functionalities. Anti-lock Braking Systems (ABS) use embedded controllers to regulate brake pressure, preventing skidding on slippery roads and enhancing vehicle stability. Similarly, adaptive cruise control systems utilize embedded microcontrollers to monitor vehicle speed and distance through RADAR or LIDAR sensors, enabling intelligent speed adjustments. Another safety-critical application is the airbag control system, which relies on real-time sensor data to trigger airbag deployment within milliseconds during a collision.\nIn industrial automation, embedded systems are central to the operation of robotic arms, conveyor belts, and assembly lines. These systems handle precise sequencing, closed-loop control, and real-time signal processing to maintain efficiency and safety. For example, industrial robots are programmed to carry out repetitive tasks such as welding, painting, and packaging, each controlled by embedded microcontrollers to ensure accuracy and reliability.\nConsumer electronics also heavily rely on embedded systems. Devices such as programmable engineering calculators, automated teller machines (ATMs), and smart home appliances incorporate microcontrollers to perform specific tasks seamlessly. Modern washing machines, for instance, utilize embedded controllers to monitor water levels, manage wash cycles, and adjust spin speeds dynamically. Similarly, ATMs use embedded microcontrollers to process transactions securely while managing input and output operations.\nBLE microcontrollers have further extended the capabilities of embedded systems by enabling low-power wireless communication. BLE technology is particularly advantageous in battery-operated devices like fitness trackers, smart home sensors, and medical monitoring equipment. These microcontrollers facilitate energy-efficient data transmission, allowing devices to remain functional for extended periods without frequent battery replacements.",
    "crumbs": [
      "Embedded Systems Design",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "contents/core/1_introduction.html#overview-of-efr32mg24-microcontroller",
    "href": "contents/core/1_introduction.html#overview-of-efr32mg24-microcontroller",
    "title": "1  Introduction",
    "section": "1.3 Overview of EFR32MG24 Microcontroller",
    "text": "1.3 Overview of EFR32MG24 Microcontroller\nThe EFR32MG24 microcontroller, part of Silicon Labs’ Wireless Gecko series, is specifically designed to address the growing demand for energy-efficient and high-performance wireless communication in embedded systems. Built on the ARM Cortex-M33 core, it operates at a maximum frequency of 78 MHz, delivering sufficient computational power for real-time applications while maintaining energy efficiency. The microcontroller integrates advanced hardware security features, including a hardware cryptographic accelerator and Secure Boot, ensuring robust protection against cyber threats. It supports multiple wireless protocols, with a primary focus on BLE 5.3, enabling reliable, low-power, short-range communication. The integrated radio transceiver offers industry-leading sensitivity and output power, ensuring stable connectivity even in challenging environments.\nThe EFR32MG24 is equipped with a range of analog and digital peripherals, including ADCs, DACs, timers, UART, SPI, and I2C interfaces, providing flexible options for sensor integration and peripheral control. Its low-power modes, combined with energy-saving peripherals and Sleep Timer capabilities, make it highly suitable for battery-operated devices such as IoT sensor nodes, wearable electronics, and smart home devices. This also features an on-chip AI/ML hardware accelerator, enabling edge-computing capabilities for tasks like sensor data analysis and anomaly detection. Hence, this microcontroller, available in the xG24-DK2601B Development Kit, is chosen for this book.",
    "crumbs": [
      "Embedded Systems Design",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "contents/core/2_programmingwithc.html",
    "href": "contents/core/2_programmingwithc.html",
    "title": "2  Programming Embedded Systems with C",
    "section": "",
    "text": "2.1 Simplicity Studio IDE for Silicon Labs EFR32XG24 Microcontroller\nSimplicity Studio is the official Integrated Development Environment (IDE) provided by Silicon Labs for embedded development with their microcontrollers, including the EFR32XG24 BLE microcontroller to be covered in this textbook. It is a feature-rich platform designed to streamline the development process, offering a library of example projects, application templates, and related tools for writing, debugging, profiling, and deploying firmware applications efficiently. It integrates multiple tools into one unified interface:\nSimplicity Studio supports a range of compilers tailored for embedded systems:\nFor the EFR32XG24 microcontroller, GCC is the default compiler bundled with Simplicity Studio, offering robust optimization and compatibility with ARM Cortex-M33 cores.",
    "crumbs": [
      "Embedded Systems Design",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Programming Embedded Systems with C**</span>"
    ]
  },
  {
    "objectID": "contents/core/2_programmingwithc.html#simplicity-studio-ide-for-silicon-labs-efr32xg24-microcontroller",
    "href": "contents/core/2_programmingwithc.html#simplicity-studio-ide-for-silicon-labs-efr32xg24-microcontroller",
    "title": "2  Programming Embedded Systems with C",
    "section": "",
    "text": "Project Management: Create, organize, and manage embedded projects.\nDevice Configuration: Configure peripheral modules and optimize hardware settings.\nDebugging Tools: Real-time debugging with SEGGER J-Link integration.\nEnergy Profiler: Monitor and optimize power consumption of embedded applications.\nWireless Network Analyzer: Analyze wireless traffic and optimize communication protocols.\n\n\n\nGCC (GNU Compiler Collection): Open-source compiler widely used in embedded systems.\nIAR Embedded Workbench Compiler: Commercial compiler known for its optimization capabilities.\nKeil ARM Compiler (ARMCC): Industry-standard compiler for ARM Cortex-M series microcontrollers.\n\n\n\n2.1.1 Development Workflow in Simplicity Studio\nThe typical workflow when using Simplicity Studio for EFR32XG24 development involves:\n\nDevice Selection: Select the target microcontroller (EFR32XG24) from the device catalog.\nProject Creation: Use templates or start from scratch to create firmware projects.\nPeripheral Configuration: Use the graphical configuration tool to set up GPIO, timers, UART, SPI, etc.\nCode Generation: Auto-generate initialization code based on configuration settings.\nBuild and Compile: Compile code using GCC or other selected compilers.\nDebug and Test: Use SEGGER J-Link debugger for step-by-step debugging and breakpoint management.\nEnergy Profiling: Use the energy profiler to optimize power consumption.\n\n\n\n2.1.2 Key Features of Simplicity Studio for EFR32XG24\nThe Graphical Peripheral Configuration Tool provides an intuitive interface for configuring peripherals and pin assignments, reducing setup errors. The Real-Time Energy Profiler enables precise monitoring and analysis of energy consumption, helping developers optimize power efficiency. The Wireless Network Analyzer facilitates debugging and fine-tuning of Bluetooth communication channels, ensuring reliable wireless connectivity. Additionally, Simplicity Studio includes SDK Integration with pre-built libraries and frameworks for BLE and IoT applications. Developers can also leverage an Extensive Example Codebase, which contains numerous pre-written projects for rapid prototyping and reduced development time.\nTo maximize productivity and ensure reliable outcomes, developers should follow established best practices when using Simplicity Studio. It is essential to keep the IDE updated to the latest version to benefit from bug fixes and new features. The graphical configuration tools should be used whenever possible to minimize errors during peripheral setup. Compiler optimizations should be enabled to account for the resource-constrained nature of embedded environments. Regular energy profiling should be conducted throughout firmware development to identify and address power inefficiencies. Lastly, developers should use the SEGGER J-Link Debugger for precise, real-time debugging and analysis of embedded applications.",
    "crumbs": [
      "Embedded Systems Design",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Programming Embedded Systems with C**</span>"
    ]
  },
  {
    "objectID": "contents/core/2_programmingwithc.html#structure-of-an-embedded-c-program",
    "href": "contents/core/2_programmingwithc.html#structure-of-an-embedded-c-program",
    "title": "2  Programming Embedded Systems with C",
    "section": "2.2 Structure of an Embedded C Program",
    "text": "2.2 Structure of an Embedded C Program\nA typical embedded C program follows a standardized structure to maintain clarity, modularity, and efficient hardware interaction. A common format that is found in Arduino IDE is as follows:\n#include &lt;stdint.h&gt;\n#define LED_PIN 13\n\nvoid init();\nvoid loop();\n\nint main() {\n    init();\n    while (1) {\n        loop();\n    }\n}\n\nvoid init() {\n    // Initialization code\n}\n\nvoid loop() {\n    // Main functionality code\n}\nAt the core lies the main() function, which serves as the entry point for program execution. The program begins with an init() function, responsible for hardware and peripheral initialization, such as configuring GPIO pins, timers, and communication interfaces. Following initialization, the program enters an infinite while(1) loop, where the loop() function is repeatedly called to handle the system’s primary tasks. This structure separates setup and runtime logic, promoting code readability and easier debugging. The use of #include &lt;stdint.h&gt; ensures access to fixed-width integer types, while the #define LED_PIN 13 macro simplifies hardware pin configuration. This modular design allows embedded systems to maintain deterministic behavior.",
    "crumbs": [
      "Embedded Systems Design",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Programming Embedded Systems with C**</span>"
    ]
  },
  {
    "objectID": "contents/core/2_programmingwithc.html#structure-of-an-embedded-c-program-in-simplicity-studio",
    "href": "contents/core/2_programmingwithc.html#structure-of-an-embedded-c-program-in-simplicity-studio",
    "title": "2  Programming Embedded Systems with C",
    "section": "2.3 Structure of an Embedded C Program in Simplicity Studio",
    "text": "2.3 Structure of an Embedded C Program in Simplicity Studio\nIn Simplicity Studio, an embedded C program adheres to a standardized structure designed to ensure modularity, hardware abstraction, and efficient execution on microcontrollers like the EFR32XG24. A typical program format is shown below:\n#include \"em_device.h\"\n#include \"em_chip.h\"\n#include \"em_gpio.h\"\n\n#define LED_PIN 13\n\nvoid init();\nvoid loop();\n\nint main(void) {\n    CHIP_Init(); // Initialize the microcontroller system\n    init();\n    while (1) {\n        loop();\n    }\n}\n\nvoid init() {\n    // GPIO and peripheral initialization code\n}\n\nvoid loop() {\n    // Main functionality code\n}\nIn Simplicity Studio, the CHIP_Init() function is typically called at the beginning of the main() function to configure essential hardware components, including the clock management unit (CMU) and device-specific registers. The init() function follows, serving to initialize peripherals, configure GPIO pins, and set up timers or communication interfaces. The program then enters an infinite while(1) loop, where the loop() function repeatedly executes core tasks. Header files such as em_device.h provide device-specific definitions, while em_chip.h ensures system-level configurations are applied. The use of predefined macros like #define LED_PIN 13 simplifies hardware abstraction, improving code clarity and reducing errors. This structure leverages Simplicity Studio’s hardware abstraction layer (HAL) to provide a consistent programming interface, ensuring scalability and portability across Silicon Labs microcontroller families.",
    "crumbs": [
      "Embedded Systems Design",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Programming Embedded Systems with C**</span>"
    ]
  },
  {
    "objectID": "contents/core/2_programmingwithc.html#generic-data-types-in-embedded-systems",
    "href": "contents/core/2_programmingwithc.html#generic-data-types-in-embedded-systems",
    "title": "2  Programming Embedded Systems with C",
    "section": "2.4 Generic Data Types in Embedded Systems",
    "text": "2.4 Generic Data Types in Embedded Systems\nData types in embedded systems are carefully chosen based on performance requirements, memory constraints, and application-specific needs. Common data types include:\n\nInteger Data Types (ISO C99 Standard)\n\nint: Standard integer type, typically 16 or 32 bits depending on the microcontroller.\nuint8_t, uint16_t, uint32_t: Unsigned integer types offering precise control over memory usage.\nint8_t, int16_t, int32_t: Signed integer types for representing both positive and negative values.\n\n\n\nFloating-Point Data Types (IEEE 754 Standard)\n\nfloat: 32-bit floating-point type for representing decimal values.\ndouble: 64-bit floating-point type for higher precision.\n\nA summary of these types is displayed in Table 2.1.\nThe EFR32XG24 microcontroller includes an FPU (Floating-Point Unit) to handle floating-point calculations, but such operations can introduce performance and power efficiency overhead. Therefore, floating-point types should be used sparingly in embedded applications.\n\n\nCommonly used integer types when programming embedded systems\n\n\n\n\n\n\n\n\nData type\nSize\nRange min\nRange max\n\n\n\n\nint8_t\n8 bits (1 byte)\n-128\n127\n\n\nuint8_t\n8 bits (1 byte)\n0\n255\n\n\nint16_t\n16 bits (2 bytes)\n-32768\n32767\n\n\nuint16_t\n16 bits (2 bytes)\n0\n65535\n\n\nint32_t\n32 bits (4 bytes)\n-2,147,483,648\n2,147,483,647\n\n\nuint32_t\n32 bits (4 bytes)\n0\n4,294,967,295\n\n\nint64_t\n64 bits (8 bytes)\n-9,223,372,036,854,775,808\n9,223,372,036,854,775,807\n\n\nuint64_t\n64 bits (8 bytes)\n0\n18,446,744,073,709,551,615",
    "crumbs": [
      "Embedded Systems Design",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Programming Embedded Systems with C**</span>"
    ]
  },
  {
    "objectID": "contents/core/2_programmingwithc.html#choosing-the-right-data-type",
    "href": "contents/core/2_programmingwithc.html#choosing-the-right-data-type",
    "title": "2  Programming Embedded Systems with C",
    "section": "2.5 Choosing the Right Data Type",
    "text": "2.5 Choosing the Right Data Type\nSelecting an appropriate data type in embedded systems programming is a crucial step to ensure optimal memory usage, computational efficiency, and prevention of data-related errors. The choice of data type must balance several key factors, including:\n\nPerformance: Larger data types consume more memory and require longer processing times.\nOverflow: Variables must be chosen to prevent exceeding their maximum allowable value.\nCoercion and Truncation: Automatic type conversion can lead to unintended behavior if not managed carefully.\n\nIn embedded systems, memory is a scarce resource, and improper data type selection can lead to unnecessary overhead. For example:\n\nOn an 8-bit microcontroller, using a 4-byte int instead of a 1-byte char for a simple counter wastes memory and processing cycles. For example,\nint counter = 0; // Uses 4 bytes unnecessarily on an 8-bit system\nuint8_t counter = 0; // Optimized for an 8-bit system\nOn a 32-bit microcontroller like the ARM Cortex-M, memory access is optimized for 4-byte alignment, and using smaller data types may not yield significant performance improvements.\n\n\nHandling Overflow\nOverflow occurs when a variable exceeds the maximum value that can be stored in its data type. In embedded systems, overflow can lead to unpredictable behavior or silent data corruption. For example:\nuint8_t seconds = 255; \nseconds += 1; // Overflow occurs, seconds resets to 0\nTo prevent overflow:\n\nUse larger data types if overflow is anticipated.\nImplement overflow detection mechanisms.\n\n\n\nData Coercion and Truncation\nIn embedded C, implicit type conversions (coercion) and truncation can lead to unintended results:\n\nWhen a smaller data type is promoted to a larger data type (e.g., uint8_t to uint16_t), padding may occur. For example,\nuint8_t smallValue = 200;\nuint16_t largeValue = smallValue; // Coercion from 8-bit to 16-bit\nWhen a larger data type is truncated to a smaller one (e.g., uint16_t to uint8_t), significant data loss may occur. For example,\nuint16_t largeValue = 1025;\nuint8_t smallValue = largeValue; // Truncation, smallValue = 1\n\n\n\nBest Practices for Data Type Selection\n\nUse fixed-width integer types from the stdint.h library (int8_t, uint16_t, etc.).\nAvoid mixing signed and unsigned data types in arithmetic operations.\nBe explicit in type casting and ensure expected results are validated.\nAlways check compiler warnings related to type conversions.",
    "crumbs": [
      "Embedded Systems Design",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Programming Embedded Systems with C**</span>"
    ]
  },
  {
    "objectID": "contents/core/2_programmingwithc.html#memory-alignment-in-embedded-systems",
    "href": "contents/core/2_programmingwithc.html#memory-alignment-in-embedded-systems",
    "title": "2  Programming Embedded Systems with C",
    "section": "2.6 Memory Alignment in Embedded Systems",
    "text": "2.6 Memory Alignment in Embedded Systems\nEfficient memory alignment is critical in embedded systems to optimize performance, reduce access latency, and ensure compatibility with the processor’s architecture. In microcontrollers like the EFR32XG24, unaligned memory access can lead to performance penalties or even cause system faults on certain architectures.\n\nUnderstanding Memory Alignment\n\nAligned Access: Data is stored in memory at addresses that are multiples of its size. For example:\n\nA 2-byte short int should be stored at an address divisible by\n\n\n\nA 4-byte int or float should be stored at an address divisible by 4.\n\nUnaligned Access: Data is stored at an address that does not adhere to its size requirements. For example:\n\nStoring a 4-byte int at an address like 0x20000003 is considered unaligned.\n\n\nAligned access is preferred because microcontrollers fetch data in word-sized chunks (e.g., 4 bytes on ARM Cortex-M processors). Misaligned data may require multiple memory accesses, increasing latency and power consumption.\n\n\nExample of Memory Alignment\nAligned Memory Example (Efficient Access):\nunsigned char a;       // 1-byte aligned at 0x20000000\nunsigned short b;      // 2-byte aligned at 0x20000002\nunsigned int c;        // 4-byte aligned at 0x20000004\nUnaligned Memory Example (Potential Performance Penalty):\nunsigned char a;       // Stored at 0x20000000\nunsigned short b;      // Stored at 0x20000001 (misaligned)\nunsigned int c;        // Stored at 0x20000003 (misaligned)\nAligned Memory Example (Efficient Access with Padding):\nunsigned char a;       // Stored at 0x20000000\nunsigned char padding; // Added for alignment\nunsigned short b;      // Stored at 0x20000002\nunsigned int c;        // Stored at 0x20000004\n\n\nBest Practices for Memory Alignment\n\nUse compiler directives or attributes to enforce memory alignment.\nGroup variables by size (e.g., group all char, then short, then int variables).\nAvoid unaligned data structures in performance-critical paths.\n\nCompiler Attribute Example (ARM GCC/Keil):\nstruct __attribute__((aligned(4))) AlignedStruct {\n    uint8_t a;\n    uint16_t b;\n    uint32_t c;\n};\nEfficient memory alignment reduces CPU cycles for memory fetches and avoids unnecessary overhead, making it a critical practice in embedded systems programming.\n\n\n2.6.1 Bitwise Operations\nBitwise operators are essential in embedded systems for manipulating hardware registers and performing efficient computations. These operations are fundamental for efficiently interacting with GPIO (General Purpose Input Output) registers in embedded systems. They allow precise control over individual bits, enabling configuration, status checking, and manipulation of GPIO pins without affecting other bits in the register.\nAND (&): Used for masking bits.\nOR (|): Used for setting bits.\nXOR (^): Used for toggling bits.\nNOT (~): Used for inverting bits.\nExample:\nuint8_t reg = 0b00001111;\nreg |= (1 &lt;&lt; 4); // Set the 5th bit\nreg &= ~(1 &lt;&lt; 2); // Clear the 3rd bit\n\n\n2.6.2 Bitwise Shift Operations\nShift operators move bits left (&lt;&lt;) or right (&gt;&gt;) and are commonly used for:\n\nMultiplying or dividing numbers by powers of two.\nSetting or clearing specific bits.\n\nExample:\nuint8_t value = 0x01;\nvalue &lt;&lt;= 3; // Shift left by 3 bits (Result: 0x08)\n\n\n2.6.3 Atomic Register Usage for GPIO Control\nAtomic GPIO operations are critical in embedded systems where precise and thread-safe pin manipulation is required. Unlike standard DOUT register operations (data directly outputs to pin), atomic registers (SET, CLR, and TGL) allow direct modification of specific bits without requiring a read-modify-write cycle.\n\nAdvantages of Atomic GPIO Operations\n\nThread-Safe: Prevents unintended side effects in concurrent operations.\nEfficient: Eliminates the overhead of read-modify-write cycles.\nPrecision: Ensures only the target bit is modified.\n\n\n\nKey Atomic Registers\n\nSET Register: Sets specific GPIO pins to a high state without affecting others.\nCLR Register: Clears specific GPIO pins to a low state without affecting others.\nTGL Register: Toggles specific GPIO pins without affecting others.\n\n\n\nAtomic Operations Examples (Explanation in Section 2.6)\n1. Setting Multiple Pins Atomically:\nGPIO-&gt;P_SET[gpioPortB].DOUT = (1 &lt;&lt; 2) | (1 &lt;&lt; 4); // Set pins 2 and 4 on Port B\n2. Clearing Specific Pins Atomically:\nGPIO-&gt;P_CLR[gpioPortC].DOUT = (1 &lt;&lt; 5); // Clear pin 5 on Port C\n3. Toggling Multiple Pins Atomically:\nGPIO-&gt;P_TGL[gpioPortD].DOUT = (1 &lt;&lt; 1) | (1 &lt;&lt; 3); // Toggle pins 1 and 3 on Port D\n\n\nAvoiding Race Conditions in GPIO Control\nIn real-time systems, race conditions can occur when multiple threads or interrupt routines attempt to modify GPIO pins simultaneously. Atomic registers mitigate this risk by ensuring:\n\nOnly the targeted pins are modified.\nNo unintended overwrites occur during concurrent access.\n\nExample of Thread-Safe Pin Toggle:\nvoid toggleLedThreadSafe(void) {\n    GPIO-&gt;P_TGL[gpioPortA].DOUT = (1 &lt;&lt; 6); // Safely toggle pin 6\n}\n\n\nBest Practices for Using Atomic Registers\n\nPrefer atomic registers for time-critical pin operations.\nAvoid mixing standard DOUT operations with atomic operations on the same pins.\nDocument atomic operations in shared resources clearly.\nTest interrupt-driven routines for predictable behavior with atomic GPIO controls.\n\n\n\nChecking the State of a GPIO Pin:\nuint8_t pinState = (GPIO-&gt;P[gpioPortA].DIN &gt;&gt; 3) & 1; // Read state of pin 3\n\n\nUsing Shift Operators for Pin Masking\nShift operators are commonly used to create masks for setting, clearing, or toggling specific bits in GPIO registers.\nExample - Setting Multiple Pins:\nGPIO-&gt;P[gpioPortA].DOUT |= (1 &lt;&lt; 3) | (1 &lt;&lt; 5); // Set pins 3 and 5\nExample - Clearing Multiple Pins:\nGPIO-&gt;P[gpioPortA].DOUT &= ~((1 &lt;&lt; 3) | (1 &lt;&lt; 5)); // Clear pins 3 and 5\n\n\nPractical Example: Blinking an LED Using Bitwise Operations\nThe following example demonstrates how to blink an LED connected to Port D, Pin 2 using bitwise operations:\n#define LED_PIN 2\n\n// Configure pin as output\nGPIO-&gt;P[gpioPortD].MODEL |= (1 &lt;&lt; (4 * LED_PIN)); // MODEL is the MODE Low register\n\n// Toggle the LED state in a loop\nwhile (1) {\n    GPIO-&gt;P[gpioPortD].DOUT ^= (1 &lt;&lt; LED_PIN); // Toggle LED pin\n    delay(1000); // 1-second delay\n}\n\n\nBest Practices for Bitwise GPIO Operations\n\nAlways mask the specific bits you intend to modify.\nAvoid direct assignments to GPIO registers; prefer bitwise operations.\nUse clear and descriptive macros for pin numbers and masks.\nTest configurations thoroughly to prevent accidental overwrites.\n\nBitwise operations provide low-level control over GPIO registers, ensuring efficient and predictable manipulation of hardware pins. Mastering these operations is essential for embedded systems programming.",
    "crumbs": [
      "Embedded Systems Design",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Programming Embedded Systems with C**</span>"
    ]
  },
  {
    "objectID": "contents/core/2_programmingwithc.html#understanding-the---operator-in-atomic-gpio-operations",
    "href": "contents/core/2_programmingwithc.html#understanding-the---operator-in-atomic-gpio-operations",
    "title": "2  Programming Embedded Systems with C",
    "section": "2.7 Understanding the -> Operator in Atomic GPIO Operations",
    "text": "2.7 Understanding the -&gt; Operator in Atomic GPIO Operations\nIn embedded systems programming, especially when interfacing with hardware peripherals such as GPIO registers, it is common to encounter expressions utilizing the -&gt; operator. This operator is used to access members of a structure through a pointer. In the context of atomic GPIO operations with the Silicon Labs EFR32XG24 microcontroller, the -&gt; operator simplifies hardware register access and enhance code clarity.\n\n2.7.1 Pointer to Structure and the -&gt; Operator\nIn C, the -&gt; operator is used to access a member of a structure when the structure is referred to by a pointer. The syntax is:\npointer-&gt;member\nThis is equivalent to:\n(*pointer).member\nHere:\n\npointer: Points to a structure (e.g., GPIO peripheral base address).\nmember: Represents a specific field in the structure (e.g., registers like P_SET, P_CLR, P_TGL).\n\n\n\n2.7.2 GPIO Structure and Enums in EFR32XG24\nThe GPIO peripheral on the EFR32XG24 microcontroller is represented as a structure, typically defined in the hardware abstraction layer (HAL). For example:\ntypedef struct {\n    volatile uint32_t DOUT;\n    volatile uint32_t SET;\n    volatile uint32_t CLR;\n    volatile uint32_t TGL;\n} GPIO_Port_TypeDef;\nAdditionally, GPIO ports are often enumerated for easy reference:\ntypedef enum {\n    gpioPortA,\n    gpioPortB,\n    gpioPortC,\n    gpioPortD\n} GPIO_Port_Type;\n\n\n2.7.3 Atomic GPIO Operations with -&gt;\nWhen performing atomic GPIO operations, the structure pointer enables access to specific GPIO port registers. For example:\nGPIO-&gt;P_SET[gpioPortB].DOUT = (1 &lt;&lt; 2) | (1 &lt;&lt; 4);\nExplanation:\n\nGPIO: Base pointer to the GPIO peripheral structure.\nP_SET: Array of registers representing SET operations for each port.\ngpioPortB: Index to select Port B.\nDOUT: Data Output register for atomic SET operation.\n\nSimilarly:\nGPIO-&gt;P_CLR[gpioPortC].DOUT = (1 &lt;&lt; 5); // Clear pin 5 on Port C\nGPIO-&gt;P_TGL[gpioPortD].DOUT = (1 &lt;&lt; 1) | (1 &lt;&lt; 3); // Toggle pins 1 and 3 on Port D\n\n\n2.7.4 Advantages of Using Structures and the -&gt; Operator\n\nCode Clarity: Clear and readable syntax for hardware register access.\nPortability: Standardized structure definitions across different microcontrollers.\nEfficiency: Direct register access through pointer dereferencing minimizes CPU cycles.",
    "crumbs": [
      "Embedded Systems Design",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Programming Embedded Systems with C**</span>"
    ]
  },
  {
    "objectID": "contents/core/2_programmingwithc.html#exercise-multiple-choice-questions",
    "href": "contents/core/2_programmingwithc.html#exercise-multiple-choice-questions",
    "title": "2  Programming Embedded Systems with C",
    "section": "2.8 Exercise: Multiple Choice Questions",
    "text": "2.8 Exercise: Multiple Choice Questions\n\nWhat is the primary reason C is preferred for embedded systems programming?\n\nUser-friendly syntax\nHigh-level abstraction\nLow-level hardware access and efficiency\nAutomatic memory management\n\nCorrect Answer: C\nWhich header file is commonly included in an embedded C program for fixed-width integer types?\n\nstdio.h\nstdint.h\nstring.h\nstdlib.h\n\nCorrect Answer: B\nWhat happens if a variable exceeds the maximum value of its data type?\n\nIt goes back to zero\nIt causes a system crash\nIt triggers an interrupt\nIt generates a compiler warning\n\nCorrect Answer: A\nWhich data type is best suited for a counter variable on an 8-bit microcontroller?\n\nint\nuint8_t\nfloat\ndouble\n\nCorrect Answer: B\nWhat is the key advantage of using floating-point data types sparingly in embedded systems?\n\nReduced memory usage\nIncreased processing speed\nBetter precision\nSimplified syntax\n\nCorrect Answer: A\nWhich of the following is an example of memory alignment in embedded systems?\n\nAddress divisible by 2 for a short integer\nRandomly allocated memory address\nUsing dynamic memory allocation\nOverwriting stack memory\n\nCorrect Answer: A\nWhat does the bitwise ‘AND’ operator do in GPIO manipulation?\n\nSets specific bits\nClears specific bits\nMasks specific bits\nToggles specific bits\n\nCorrect Answer: C\nWhat is the purpose of the ‘SET’ register in GPIO control?\n\nClear specific GPIO pins\nToggle specific GPIO pins\nSet specific GPIO pins\nRead GPIO pin status\n\nCorrect Answer: C\nWhich best describes data coercion in embedded systems?\n\nAutomatic type conversion\nForced memory alignment\nManual data truncation\nDynamic memory reallocation\n\nCorrect Answer: A\nWhat happens when a uint16_t variable is assigned to a uint8_t variable with a value greater than 255?\n\nValue remains unchanged\nCompiler error\nValue is truncated\nSystem crash\n\nCorrect Answer: C\nWhich of the following prevents race conditions in GPIO control?\n\nUsing ‘DOUT’ register\nUsing ‘SET’ and ‘CLR’ registers atomically\nDisabling interrupts\nUsing global variables\n\nCorrect Answer: B\nWhy is aligned memory access preferred in embedded systems?\n\nBetter energy efficiency\nIncreased memory usage\nReduced CPU latency\nDynamic memory allocation\n\nCorrect Answer: C\nWhat is the main function of bitwise shift operators (‘&lt;&lt;’ and ‘&gt;&gt;’) in embedded C?\n\nInverting bits\nMultiplying or dividing by powers of two\nClearing specific bits\nReading GPIO pin status\n\nCorrect Answer: B\nWhat should you avoid when working with GPIO atomic operations?\n\nMixing standard ‘DOUT’ and atomic operations\nUsing specific masks\nDocumenting shared resources\nTesting configurations\n\nCorrect Answer: A\nWhich fixed-width integer type ensures consistent size across platforms?\n\nint\nlong\nuint16_t\nshort\n\nCorrect Answer: C",
    "crumbs": [
      "Embedded Systems Design",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**Programming Embedded Systems with C**</span>"
    ]
  },
  {
    "objectID": "contents/core/3_devkitoverview.html",
    "href": "contents/core/3_devkitoverview.html",
    "title": "3  EFR32xG24 Development Kit Overview",
    "section": "",
    "text": "3.1 Key Features of the EFR32xG24 Development Kit\nThe EFR32xG24 Development Kit (xG24-DK2601B) is a versatile platform designed for prototyping and evaluating applications using the EFR32MG24 Wireless Gecko System-on-Chip (SoC), EFR32MG24B310F1536IM48-B. It serves as an ideal platform for developing energy-efficient IoT devices, offering advanced hardware features, debugging capabilities, and seamless integration with development tools such as Simplicity Studio. It also contains a built-in AI/ML Hardware Accelerator.\nThe key components and features of this kit include:",
    "crumbs": [
      "Embedded Systems Design",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**EFR32xG24 Development Kit Overview**</span>"
    ]
  },
  {
    "objectID": "contents/core/3_devkitoverview.html#key-features-of-the-efr32xg24-development-kit",
    "href": "contents/core/3_devkitoverview.html#key-features-of-the-efr32xg24-development-kit",
    "title": "3  EFR32xG24 Development Kit Overview",
    "section": "",
    "text": "EFR32MG24 Wireless Gecko SoC: ARM Cortex-M33 processor operating at 78 MHz, with 1536 KB Flash and 256 KB RAM.\nConnectivity: High-performance 2.4 GHz radio for Bluetooth and other wireless protocols.\nOn-Board Sensors:\n\nSi7021 Relative Humidity and Temperature Sensor.\nSi7210 Hall Effect Sensor.\nICS-43434 MEMS Stereo Microphones.\nICM-20689 6-Axis Inertial Sensor.\nVEML6035 Ambient Light Sensor.\nBMP384 Barometric Pressure Sensor.\n\nMemory: 32 Mbit external SPI flash for Over-The-Air (OTA) firmware updates and data logging.\nPower Options: USB, coin cell battery (CR2032), or external battery.\nDebugging Tools:\n\nSEGGER J-Link On-Board Debugger.\nPacket Trace Interface (PTI).\nMini Simplicity Connector for advanced debugging.\n\nUser Interface: Two push buttons, an RGB LED, and a virtual COM port.\nConnectivity Interfaces: I2C, SPI, UART, and Qwiic Connector.\n\n\n3.1.1 Development Environment and Tools\nThe development kit is fully supported by Silicon Labs’ Simplicity Studio, an integrated development environment (IDE) offering:\n\nProject creation and device configuration.\nReal-time energy profiling and debugging tools.\nWireless network analysis with Packet Trace Interface (PTI).\nPre-built example projects and libraries for rapid prototyping.\n\n\n\n3.1.2 Power Management\nThe kit offers flexible power options, including:\n\nUSB power supply through a Micro-B connector.\nCoin cell battery (CR2032) for portable applications.\nExternal battery via a dedicated header.\nAutomatic power source switchover for seamless transitions.\n\nExample Configuration for USB Power Supply:\nPower supplied via USB Micro-B connector:\n- VBUS regulated to 3.3V for SoC and peripherals.\n- Automatic switchover when USB is connected.\n\n\n3.1.3 Debugging and Virtual COM Port\nThe built-in SEGGER J-Link debugger allows:\n\nOn-chip debugging via Serial Wire Debug (SWD) interface.\nReal-time packet trace using Packet Trace Interface (PTI).\nSerial communication using Virtual COM Port (VCOM).\n\nExample UART Configuration for VCOM:\nBaud rate: 115200 bps\nData bits: 8\nParity: None\nStop bits: 1\n\n\n3.1.4 GPIO and Peripheral Access\nThe development kit provides 20 breakout pads, exposing GPIO pins, I2C, UART, and SPI interfaces. These pads follow the EXP header pinout standard, ensuring compatibility with expansion boards. Each sensor is optimized for low power consumption.\n\n\n3.1.5 Best Practices for Overall Project Development\n\nUse Simplicity Studio for project management and debugging.\nEnable only necessary peripherals to conserve power.\nUse GPIO atomic operations for time-critical applications.\nValidate sensor connections using test scripts.",
    "crumbs": [
      "Embedded Systems Design",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**EFR32xG24 Development Kit Overview**</span>"
    ]
  },
  {
    "objectID": "contents/core/3_devkitoverview.html#sensors-and-interfaces",
    "href": "contents/core/3_devkitoverview.html#sensors-and-interfaces",
    "title": "3  EFR32xG24 Development Kit Overview",
    "section": "3.2 Sensors and Interfaces",
    "text": "3.2 Sensors and Interfaces\nThe EFR32xG24 Development Kit integrates multiple onboard sensors interfaced through GPIO, I2C, or SPI connections, ensuring precise communication and control.\n\nSi7021 Relative Humidity and Temperature Sensor\nThe Si7021 is a high-precision digital humidity and temperature sensor featuring a factory-calibrated output and low power consumption, making it suitable for IoT and embedded applications.\nKey Features:\n\nRelative humidity accuracy: ±3%\nTemperature accuracy: ±0.4°C\nOperating voltage: 1.9V to 3.6V\nUltra-low standby current: 60 nA\n\nApplications:\n\nEnvironmental monitoring systems\nHVAC control\nSmart home automation\n\nThe sensor is connected through I2C, and its thermal isolation reduces self-heating effects, ensuring more accurate temperature readings.\n\n\nSi7210 Hall Effect Sensor\nThe Si7210 is a highly sensitive Hall effect sensor capable of detecting magnetic field changes with excellent precision. It is often used in applications requiring contactless position sensing.\nKey Features:\n\nMagnetic sensitivity: ±2.5 mT\nI2C communication interface\nProgrammable magnetic thresholds\nFactory-calibrated accuracy\n\nApplications:\n\nProximity sensing\nPosition detection\nReed switch replacement\n\nThe Si7210 offers real-time magnetic field measurements and is configured via the I2C bus.\n\n\nICS-43434 MEMS Stereo Microphones\nThe ICS-43434 microphones are omnidirectional MEMS microphones with I2S digital output. They are suitable for audio signal processing and voice recognition systems.\nKey Features:\n\nFrequency response: 50 Hz – 20 kHz\nDigital I2S output\nLow power consumption\nHigh Signal-to-Noise Ratio (SNR)\n\nApplications:\n\nVoice recognition systems\nAcoustic event detection\nEnvironmental noise monitoring\n\nThe microphones are mounted on the bottom side of the development board, with sound pathways designed for optimal acoustic performance.\n\n\nICM-20689 6-Axis Inertial Sensor\nThe ICM-20689 integrates a 3-axis gyroscope and a 3-axis accelerometer for precise motion and orientation tracking.\nKey Features:\n\n3-axis gyroscope and 3-axis accelerometer\nProgrammable digital filters\nIntegrated 16-bit ADC\nSPI interface for high-speed communication\n\nApplications:\n\nMotion detection systems\nGesture-based controls\nOrientation tracking\n\nThe sensor is positioned near the geometrical center of the board, minimizing measurement bias caused by physical placement.\n\n\nVEML6035 Ambient Light Sensor\nThe VEML6035 is a high-precision ambient light sensor that supports a digital I2C interface. It is designed for automatic brightness control and energy-saving applications.\nKey Features:\n\nWide dynamic range\nLow power consumption\nHigh accuracy\nI2C communication\n\nApplications:\n\nDisplay backlight adjustment\nSmart lighting systems\nProximity detection\n\nThe sensor is factory-calibrated for optimal accuracy and sensitivity across a wide range of light intensities.\n\n\nBMP384 Barometric Pressure Sensor\nThe BMP384 is a high-precision absolute barometric pressure sensor with an integrated temperature sensor suitable for environmental monitoring and altitude estimation.\nKey Features:\n\nPressure accuracy: ±0.5 hPa\nTemperature accuracy: ±0.5°C\nI2C/SPI communication interface\nIntegrated noise reduction filter\n\nApplications:\n\nWeather station systems\nAltitude estimation\nDrone stabilization systems\n\nThe BMP384 sensor uses an internal noise-reduction filter to improve data accuracy during high-resolution measurements.\n\n\nBest Practices for Sensor Integration\nTo ensure optimal performance when working with the onboard sensors:\n\nAlways enable sensor power through the appropriate GPIO pins before initialization.\nAvoid floating GPIO lines connected to sensors.\nValidate sensor connections and configurations using test scripts.\nMinimize concurrent access to shared I2C or SPI lines.",
    "crumbs": [
      "Embedded Systems Design",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>**EFR32xG24 Development Kit Overview**</span>"
    ]
  },
  {
    "objectID": "contents/core/4_efr32programming.html",
    "href": "contents/core/4_efr32programming.html",
    "title": "4  EFR32 I/O Programming",
    "section": "",
    "text": "4.1 EFR32XG24 GPIO Overview\nAs displayed in Figure 4.1, the EFR32XG24 microcontroller series includes multiple GPIO ports (A, B, C, and D), with each port supporting up to 16 pins. The key GPIO ports and pins that are available on the specific chip used in the EFR32XG24 Dev Kit are:\nEach GPIO pin can be individually configured for various modes, including input, output, and alternate functions.\nNote that on the EFR32XG24 Dev Kit, only some pins are broken out, that is, available for use via the expansion headers on the left and right sides of the board. These pins on the expansion header, which may be found in the EFR32XG24 Dev Kit User Guide on page 19 are displayed in Figure 4.2.",
    "crumbs": [
      "Embedded Systems Design",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**EFR32 I/O Programming**</span>"
    ]
  },
  {
    "objectID": "contents/core/4_efr32programming.html#efr32xg24-gpio-overview",
    "href": "contents/core/4_efr32programming.html#efr32xg24-gpio-overview",
    "title": "4  EFR32 I/O Programming",
    "section": "",
    "text": "PA00-PA09\nPB00-PB05\nPC00-PC09\nPD00-PD05\n\n\n\n\n4.1.1 Clock Management Unit (CMU)\nThe Clock Management Unit (CMU) controls the clock signals for various peripherals, including GPIO. Before using GPIO, its corresponding clock must be enabled by setting the appropriate bit in the CMU_CLKEN0 register:\nCMU-&gt;CLKEN0 |= 1 &lt;&lt; 26;\nThis ensures that the GPIO module is both powered up and ready for use with a clock connected.\nThe CMU_CLKEN0 register also allows activating the clock to other peripherals through the use of the same code as above. The only required change is the bit to modify, by changing the number of bits to shift the 1 left to one of the options shown in Figure 4.3.\n\n\n\nFigure 4.1: Pinout of QFN-48 packaged EFR32MG24 microcontroller (EFR32MG24 Datasheet page 107)\n\n\n\n\n\nFigure 4.2: EFR32XG24 Dev Kit Expansion Header Pinout (UG524 page 19)\n\n\n\n\n\nFigure 4.3: Peripherals available to enable in the CMU_CLKEN0 register (Reference manual page 173)\n\n\n\n\n\nFigure 4.4: The MODEL and MODEH registers for EFR32MG24 GPIO Port A (Reference manual page 851)\n\n\n\n\n4.1.2 GPIO Configuration\nEach GPIO pin can serve multiple functions controlled by the MODEL and MODEH registers:\n\nMODEL: Configures pins 0-7 of the port.\nMODEH: Configures pins 8-15 of the port.\n\nEach pin mode is represented by 4 bits, supporting modes such as:\n\n0: Disabled\n1: Input\n2: Input pull-up/down\n4: Push-pull (Output)\n\nIn pull-up/pull-down mode, the value of the DOUT register (covered later) determines the pull direction, with a 1 being pull-up and 0 being pull-down.\nTo set a pin mode programmatically:\nGPIO-&gt;P[gpioPortX].MODEL |= mode &lt;&lt; (4 * n);\nFor pin numbers 8-15:\nGPIO-&gt;P[gpioPortX].MODEH |= mode &lt;&lt; (4 * (n - 8));\nA total of 16 pin modes are available for each GPIO pin. While many of these modes are not used in basic applications, Figure 4.5 displays all of the available options.\n\n\n\nFigure 4.5: Mode register value options for each GPIO pin (Reference manual page 851)\n\n\n\n\n4.1.3 GPIO Output Control\nGPIO output can be managed using the following registers:\n\nDOUT: Directly outputs data to pins.\nSET: Atomically sets specified bits.\nCLR: Atomically clears specified bits.\nTGL: Atomically toggles specified bits.\n\nExample of setting and clearing pins:\nGPIO-&gt;P[gpioPortD].DOUT |= 1 &lt;&lt; 2; // Set pin 2 of Port D\nGPIO-&gt;P[gpioPortD].DOUT &= ~(1 &lt;&lt; 2); // Clear pin 2 of Port D\n\n\n4.1.4 GPIO Input Control\nGPIO pins configured as inputs can be read using the DIN register:\nuint8_t pinState = (GPIO-&gt;P[gpioPortX].DIN &gt;&gt; n) & 1;\nThis reads the state of pin n and returns either 0 or 1.\n\n\n4.1.5 Using emlib for GPIO\nEFR32 provides the emlib hardware abstraction layer (HAL) for GPIO configuration:\n\nGPIO_PinModeSet(port, pin, mode)\nGPIO_PinOutSet(port, pin)\nGPIO_PinOutClear(port, pin)\nGPIO_PinOutToggle(port, pin)\nGPIO_PinInGet(port, pin)\n\nExample of setting a pin as output using emlib:\nGPIO_PinModeSet(gpioPortD, 2, gpioModePushPull); // Set the Push Pull Mode of Pin 2 of Port D\nGPIO_PinOutSet(gpioPortD, 2); // Set pin 2 of Port D\n\n\n4.1.6 Practical Example: Blinking an LED\nA simple example of GPIO programming is blinking an LED connected to a GPIO pin:\nGPIO_PinModeSet(gpioPortD, 2, gpioModePushPull);\nwhile (1) {\n    GPIO_PinOutToggle(gpioPortD, 2);\n    delay(1000);\n}\nThis toggles the LED state every second.",
    "crumbs": [
      "Embedded Systems Design",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>**EFR32 I/O Programming**</span>"
    ]
  },
  {
    "objectID": "contents/core/5_efr32applications.html",
    "href": "contents/core/5_efr32applications.html",
    "title": "5  Applications of EFR32 I/O",
    "section": "",
    "text": "5.1 7-Segment Displays\n7-segment displays are commonly found in user-facing embedded systems, such as clock radios, household appliances, vehicles, and industrial equipment. While LED status indicators are often used for simple devices, they cannot communicate detailed information such as sensor readings or error codes. Gaining traction in the 1970s with the advent of LED technology, 7-segment displays bridge the gap between basic indicator lights and more complex graphic screens, commonly offering one or multiple digits composed of seven LED digit segments plus a decimal point or colon.",
    "crumbs": [
      "Embedded Systems Design",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Applications of EFR32 I/O**</span>"
    ]
  },
  {
    "objectID": "contents/core/5_efr32applications.html#segment-displays",
    "href": "contents/core/5_efr32applications.html#segment-displays",
    "title": "5  Applications of EFR32 I/O",
    "section": "",
    "text": "5.1.1 Segments\n7-segment displays are composed of a group of LED segments arranged in an “8” pattern, allowing every digit from 0-9 plus a limited selection of letters to be readable.\nThese segments are commonly labeled A-G in a clockwise manner, with A being the top segment and G being the middle segment. Depending on the display, the segments may be wired in a common anode (LED positive terminal) or common cathode (LED negative terminal) configuration. Depending on the configuration, a slightly different circuit with inverted code logic may be necessary.\nAdditionally, as each segment is a simple LED, current-limiting resistors are a necessary inclusion in the circuit. In some cases, it may be acceptable to place a single resistor between in series with the common pin, especially if the resistor is of a high value to significantly limit the segment’s brightness. However, in most cases, it is ideal to adhere to the best practice of placing a current-limiting resistor in series with each segment so that manufacturing discrepancies between segments do not allow any individual segment to endanger itself with a high current.\n\n\n5.1.2 Wiring\nA 7-segment display will allocate a significant number of pins on a microcontroller, often using up nearly an entire GPIO port. If the decimal point is not used, one pin may be saved, but in many cases, it is beneficial to use a BCD to 7-segment decoder IC, such as the 74LS147, or even an 8-bit serial-in, parallel-out shift register such as the 74HC595 for greater GPIO pin efficiency. However, for the purposes of this guide, the 7-segment display will be directly connected to the microcontroller, using 8 GPIO pins.\nIn an ideal design, such as when building a PCB carrier board for the EFR32MG24 chip, a bank of pins such as PC00-PC07 may be used, allowing the GPIO port C MODEL register to be written in its entirety and full bytes written to the pin set and clear ports.\nHowever, the EFR32XG24 Dev Kit board does not break out a single port in its entirety, therefore requiring the display to share pins between Port A and Port C. Segments A-E will use PC01-PC05, while F, G, and the decimal point (DP) will be connected to PA05-PA07, as displayed in Figure 5.1. This requires in code an array of GPIO ports and pins to look up the right one for a given segment:\n// use gpioPortC (2) pins 1-5 for A-E, and gpioPortA (0) pins 5-7 for F, G, and DP\n//                               A  B  C  D  E  F  G  .\nconst uint8_t segment_ports[] = {2, 2, 2, 2, 2, 0, 0, 0};\nconst uint8_t segment_pins[] =  {1, 2, 3, 4, 5, 5, 6, 7};\n\n\n\nFigure 5.1: Wiring diagram for a single common cathode 7-segment display\n\n\n\n\n5.1.3 Digit display logic\nWith these arrays created, the pattern of segments to enable for any character can now be defined. As there are eight segments in total, it makes sense to represent these patterns as bits in a byte, allowing for straightforward storage and lookup. To construct this byte, one may represent segment A as bit 0, B as bit 1, and so on until DP is bit 7. This results in Table 5.1, displaying the construction of hexadecimal codes for digits 0-9.\n\n\nLookup table for 7-segment display digit codes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDigit\nbit 7\nbit 6\nbit 5\nbit 4\nbit 3\nbit 2\nbit 1\nbit 0\nHexadecimal\n\n\n\n.\nG\nF\nE\nD\nC\nB\nA\n\n\n\n0\n0\n0\n1\n1\n1\n1\n1\n1\n0x3F\n\n\n1\n0\n0\n0\n0\n0\n1\n1\n0\n0x06\n\n\n2\n0\n1\n0\n1\n1\n0\n1\n1\n0x5B\n\n\n3\n0\n1\n0\n0\n1\n1\n1\n1\n0x4F\n\n\n4\n0\n1\n1\n0\n0\n1\n1\n0\n0x66\n\n\n5\n0\n1\n1\n0\n1\n1\n0\n1\n0x6D\n\n\n6\n0\n1\n1\n1\n1\n1\n0\n1\n0x7D\n\n\n7\n0\n0\n0\n0\n0\n1\n1\n1\n0x07\n\n\n8\n0\n1\n1\n1\n1\n1\n1\n1\n0x7F\n\n\n9\n0\n1\n1\n0\n1\n1\n1\n1\n0x6F\n\n\n\n\nThese hexadecimal codes for each digit can then be inserted into another array, with the array index mapping a desired digit to its segment code. In a later exercise, you will be required to expand this array to support hexadecimal digits as well.\n\n\n5.1.4 Display driver code\nNow that this look-up array for digits is implemented, driving the 7-segment display is trivial. Each GPIO pin in use must be set up as an output. Each pin may then be looped through, and set or cleared depending on if its corresponding bit in the hexadecimal code is set. This can be achieved by shifting the hexadecimal code right by the loop iterator variable, then evaluating based on the bitwise AND of the shifted code and 1.\nfor (int i = 0; i &lt; 8; i++) // loop through all segments\n{ \n    if ((segments[arbitrary_digit] &gt;&gt; i) & 1) // look up hex code, shift right, AND\n    {\n        GPIO-&gt;P_SET[segment_ports[i]].DOUT = 1 &lt;&lt; segment_pins[i]; // turn on segment\n    }\n    else\n    {\n        GPIO-&gt;P_CLR[segment_ports[i]].DOUT = 1 &lt;&lt; segment_pins[i]; // turn off segment\n    }\n}\nIn this example, we use the segments array to loop up the hex code for a given arbitrary_digit, which could be an integer literal or a variable. The looked up code is shifted right based on the index of the current digit to be illuminated or turned off. With the bit of interest now moved to bit 0, it is compared with 1 to determine the appropriate state for the segment.\n\n\n5.1.5 Multiple digits\nIn many applications, multiple 7-segment digits are necessary to display a larger number or other more detailed information. Even displaying time in a 12- or 24-hour format requires four digits. Therefore, it is often beneficial to combine multiple 7-segment displays into a single module, and these are commonly available in 2, 4, 6, or 8 digit configurations. However, using 8 GPIO pins per segment can quickly waste all available microcontroller pins. Instead, all digits in a module multiplex, or share, segment pins, which means that all segments, if illuminated at the same time, would show the same character. To facilitate this multiplexing, each digit has its own separate common cathode or common anode pin, which can be connected or disconnected to power. Each digit may then be lit one after another, with only one on at a given time, and this process is constantly repeated to create the effect that all digits are constantly on.\nThis does necessitate the use of an NPN transistor for each digit to switch the common pin load of the digit on and off, as the microcontroller cannot sink this significant current into a single GPIO. An example circuit is included in Figure 5.2, demonstrating the connections of a two-digit module with a common cathode configuration to an MCU.\n\n\n5.1.6 Multiple digits logic\nThe same code may be used for driving multiple digits as a single digit; after all, the only difference is that the lit digit must be changed repeatedly. It is therefore ideal to move the single digit driver code to its own function so that it may be reused. The infinite loop must be adjusted to drive each digit’s transistor base pin high, then display a given digit, and finally switch the transistor back off before repeating the process for the next digit. This must be done quickly to avoid flicker at a frequency that is visible to the human eye, but not so quickly that the LEDs in each segment do not have time to reach their full brightness. Therefore, a few milliseconds of delay may be necessary while each digit is on before quickly switching to the next digit.\n\n\n\nFigure 5.2: Two common-cathode 7-segment display digits switches by transistors\n\n\n\n\n5.1.7 Exercise: Displaying hexadecimal numbers\nComplete Table 5.1 with the additional hexadecimal digits A-F, and expand the array. Then, try displaying 8-bit numbers in hexadecimal format with a two-digit 7-segment display module.",
    "crumbs": [
      "Embedded Systems Design",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Applications of EFR32 I/O**</span>"
    ]
  },
  {
    "objectID": "contents/core/5_efr32applications.html#parallel-lcd-displays",
    "href": "contents/core/5_efr32applications.html#parallel-lcd-displays",
    "title": "5  Applications of EFR32 I/O",
    "section": "5.2 Parallel LCD displays",
    "text": "5.2 Parallel LCD displays\nWhen more letters or symbols must be displayed to a user than is practical with a simple 7-segment display, or a graphical user interface is it is common to use a screen. Early computers generated signals to drive CRT screens, with a limited number of display lines and colors. Now, while full-color, high resolution monitors and other displays are widespread, it is still common to find smaller, often monochrome screens used in embedded systems due to their simplicity and minimal power consumption. In this section, we will learn about interfacing with a liquid crystal display (LCD) screen that can display two lines of 5x8 pixel characters. These low-cost displays are commonly found on budget 3D printers, control units for machinery, or in vehicle entertainment systems.\n\n5.2.1 16x2 Character LCD\nAn inexpensive character-based LCD module often contains 2-4 rows of 8-20 characters. In this case, the common LCD1602 module with 2 rows of 16 characters will be used. At the top of the display is a row of pins for powering and controlling the display. Table 5.2 displays details for each pin, but most commonly found on these displays are power and ground for the display, a separate anode and cathode for the backlight LED, a contrast adjustment, and a number of data and control signals. To understand how to interface with the LCD, we must examine the display’s built in controller.\n\n\n5.2.2 LCD Controller\nThe LCD module has an on-board Hitachi HD44780U controller that generates signals for the individual pixels of the display. The HD44780U is based on an original 1980s design, retaining command and feature parity while supporting modern microcontroller interfaces. It has two host-facing I/O registers as well as internal memory, meaning that data written to the display remains until it is next updated, reducing host MCU processor load. A 4- and 8-bit interface allows writing to, or reading from, both the instruction register or data register, which are used for configuration and character output, respectively. Therefore, these displays are known as using a parallel interface, as multiple bits of data are transferred at the same instant. More advanced displays may also offer additional interfaces that we will learn about later, such as I2C or SPI. It is important to read and understand the datasheet for the LCD controller to learn how to interface with it. The datasheet is linked here, but excerpts will be taken from it in this section: https://www.sparkfun.com/datasheets/LCD/HD44780.pdf\n\n\n\n\n\n\n\nFigure 5.3: Pinout for commonly available 16x2 LCD modules\n\n\n\n\nTable 5.2: Pin designations and descriptions for the 16x2 LCD display\n\n\n\n\n\n\n\nPin\nSymbol\nDescription\n\n\n\n\n1\nGND\nDisplay ground.\n\n\n2\nVCC\nDisplay power. Connect to 5V.\n\n\n3\nV0\nDisplay contrast adjustment. 0-5V range.\n\n\n4\nRS\nRegister select. 0 for instructions, 1 for data.\n\n\n5\nR/W\nRead/write. 0 for write, 1 for read.\n\n\n6\nE\nEnable. Starts data read/write operation.\n\n\n7\nD0\nData bit 0, used in 8-bit mode.\n\n\n8\nD1\nData bit 1, used in 8-bit mode.\n\n\n9\nD2\nData bit 2, used in 8-bit mode.\n\n\n10\nD3\nData bit 3, used in 8-bit mode.\n\n\n11\nD4\nData bit 4, used in 4-bit and 8-bit mode.\n\n\n12\nD5\nData bit 4, used in 4-bit and 8-bit mode.\n\n\n13\nD6\nData bit 4, used in 4-bit and 8-bit mode.\n\n\n14\nD7\nData bit 4, used in 4-bit and 8-bit mode.\n\n\n15\nA\nBacklight LED anode. Connect to 5V.\n\n\n16\nK\nBacklight LED cathode. Connect to GND.\n\n\n\n\n\n\n5.2.3 LCD Wiring\nAs referenced above, these displays support both a 4-bit and an 8-bit data transfer mode, with the 8-bit data length allowing for faster and simpler transmissions while the 4-bit data length increases software complexity but requires fewer GPIO pins to be allocated.\nIn both cases, the display also requires three additional control signals, RS, RW, and E. The RS line selects between the instruction register (if set to 0), and the data register (if set to 1) of the HD44780 controller, allowing data sent to be interpreted as a command or a character to display. The RW line configures the data pins for read or write mode, from the perspective of the host MCU. Because the display will receive commands and data from the MCU most of the time, the RW line will often be 0, however, in some cases such as reading the address of the display cursor or the display’s busy signal, this line should be brought high. Finally, the E—or enable—signal causes a data transfer to occur. When writing to the display, the data and control lines should first be set up, and then the enable line quickly toggled on then back off, causing the HD44780U to accept the command or data.\nIn total, the 4-bit data mode will use a minimum of 7 GPIOs, and the 8-bit mode a minimum of 11 GPIOs. While they are not prohibitive, these are significant pin allocations for a single peripheral, and care must be taken when designing an embedded system to make good use of available pins.\nTherefore, this section will take into account the additional complexity of the 4-bit data mode, making the 8-bit mode comparatively trivial to implement. To begin, the LCD should be connected to the EFR32XG24 Dev Kit as shown in the schematic in Figure 5.4 and the wiring diagram in Figure 5.5.\n\n\n\n\n\n\n\nFigure 5.4: Schematic diagram of LCD connections to EFR32XG24 Dev Kit\n\n\n\n\n\n\n\n\n\nFigure 5.5: Wiring diagram for LCD connections to EFR32XG24 Dev Kit\n\n\n\n\n5.2.4 LCD Data Transfer\nThe LCD accepts command and data bytes on the four or eight connected data lines, on the falling edge of a single pulse of the enable line. The three control lines and all of the data lines must first be written to, so that the data on them is valid at the time of the enable line pulse. In 8-bit mode, each pulse of the enable line corresponds with a single instruction or data. However, in 4-bit mode, two consecutive writes or reads are necessary to transmit a full command. The command’s byte must be split into two nibbles—groups of four bits— and then transmitted with the most significant bits (MSBs) 7:4 first, followed by the least significant bits (LSBs) 3:0. At the completion of the second data transfer, the LCD will execute the command and, after a brief period, be ready to accept more. The following code implements the protocol described above to send instructions or data to the LCD. Note that this code assumes that the control and data pins have already been configured as outputs.\nvoid lcd_nibble_write(uint8_t data, uint8_t register_select)\n{\n    lcd_wait(); // wait until busy flag is not set (covered later in chapter)\n\n    GPIO-&gt;P_CLR[DATA_port] = DATA_mask;               // clear data bits PC04-PC01\n    GPIO-&gt;P_SET[DATA_port] = (data &lt;&lt; 1) & DATA_mask; // set data bits shifted onto the correct pins\n\n    if (register_select) // data\n        GPIO-&gt;P_SET[CTRL_port] = 1 &lt;&lt; RS_pin;\n    else // command\n        GPIO-&gt;P_CLR[CTRL_port] = 1 &lt;&lt; RS_pin;\n\n    GPIO-&gt;P_SET[CTRL_port] = 1 &lt;&lt; EN_pin; // set enable\n    sl_sleeptimer_delay_millisecond(1);\n    GPIO-&gt;P_CLR[CTRL_port] = 1 &lt;&lt; EN_pin; // unset enable\n}\nThe lcd_nibble_write function takes two arguments, the first being the data (whether it be an instruction or character) to transmit, and the second being a boolean for the register select line. First, the function checks the LCD busy flag to determine if the LCD controller is ready to accept new data. This function will be discussed later, and may be implemented or replaced with a delay. The data lines are then cleared so that any previously sent data does not interfere with the new data to be written. As the data is expected in the lower four bits of the data byte, it is shifted into the correct position on the port based on the wiring diagram. Depending on the wrapper code for this function, an additional masking of the data may be wise to avoid tampering with other GPIO pins. The register select pin is also written to match the register_select argument, and finally the enable line toggled to complete the transmission.\n\n\n5.2.5 LCD Instructions\nSending a full command or character to the LCD just requires two calls to the already-implemented lcd_nibble_write function, one for each nibble that must be transmitted. It may be beneficial to write a wrapper function that does this automatically, requiring only the full byte of data, and potentially a register select argument to complete the entire process. This would involve shifting the data argument right four bits, calling lcd_nibble_write to transmit these MSBs, then masking out the upper four bits of the data argument and again calling lcd_nibble_write.\nWith the understanding of sending full commands to the LCD, it can now be properly initialized. To do so, it is necessary to consult the HD44780U datasheet to properly form the LCD commands. An excerpt from the datasheet is included in Figure 5.6.\n\n\n\n\n\n\n\nFigure 5.6: Instruction table for HD44780 (HD44780U Datasheet page 25)\n\n\nGoing through these instructions, it is clear that the command itself is determined by the place of the leftmost set bit.\nThe first couple of instructions at the top, Clear display and Return home, do not require arguments, and therefore require no bits lower than the leftmost set bit to change their behavior.\nThe next command, eEtry mode set, determines if the LCD’s internal DDRAM address counter is increased or decreased after a character is sent. The DDRAM address corresponds with the cursor position, so it is most common for bit 1 to be set for this command. Bit 0 in the entry mode set command controls if the display should be shifted, as in, the cursor remains in the same position on the display and all other letters scroll around it when a character is sent. This mode is sometimes useful for displaying a wide line of scrolling text.\nThe Display on/off control command allows the display itself, the cursor, and the cursor blinking to be turned on or off. Setting any of the argument bits for this command turns them on. For text entry, it is common for all three bits (2:0) to be set, giving a blinking cursor for the next character. For status or sensor reading displays, only bit 2 (entire display) should be set, as the cursor would be visually distracting in this case.\nThe Cursor or display shift command manually increments or decrements the cursor position, or shifts the entire display right or left. This may be used for a backspace action or for scrolling text.\nThe Function set command is important for initialization of the display. The data length bit (4) selects between 4- and 8-bit modes, with 0 representing 4 bits and 1 representing 8 bits. The value for this bit will depend on the wiring for the LCD chosen previously. The number of lines bit (3) configures the display controller for 1 or 2 lines of text, with 0 representing 1 line, and 1 representing 2 lines. The value for this bit should be chosen based on the LCD hardware in use. Finally, the character font bit (2) chooses between a 5x8 or 5x10 character font, and should also be chosen depending on the LCD’s capabilities.\nThe Set CGRAM address and Set DDRAM address are nearly identical, differing only in the number of bits available for the address and the RAM to write to. The CGRAM may be reconfigured while in operation with custom characters, and using the Set CGRAM address command is useful to select the custom character to overwrite. The DDRAM, which stores characters themselves that have been sent to the display, is more commonly used. Because the LCD DDRAM stores 80 character bytes, and the display is split into two lines, the second line begins at byte 40 of the DDRAM. This means that writing more than 16 characters on the first line will not automatically wrap to the second for many more characters; instead, the DDRAM address must be set to decimal 40 to begin the second line. For both commands, the address is specified in the bits lower than the leftmost set bit, and should be a valid address within the memory limits of the display controller.\nThe last command in the Figure 5.6 instruction table requires the R/W bit to be set and the data lines used as inputs to the host MCU. This command allows the LCD busy flag to be read using bit 6 of the LCD controller’s response. It also allows for the host MCU to read the LCD controller’s address counter in the lower bits 5:0.\nWhen using the 4-bit data length, each of these commands must be constructed by the MCU, then split into the high-order and low-order nibbles to send sequentially to the LCD.\n\n\n5.2.6 LCD Initialization\nWith all LCD commands accounted for, the LCD may now be initialized before use. Included in Figure 5.7 is the steps necessary to initialize the LCD in 4-bit mode.\nAt power-up, every LCD character will be fully filled in, initialized, and cleared before characters can be written to it. Based on Figure 5.7, despite the LCD being automatically reset at power on, a manual reset sequence is necessary to synchronize the nibble transmissions. This reset sequence uses only lcd_nibble_write, as it is not yet ready to receive full commands. After this reset sequence is completed, the 4-bit mode, number of lines, and character size are then set in a single function set command, and further configuration commands may be used to clear the display, move the cursor, or adjust scrolling before characters are written to the LCD for the first time.\n\n\n5.2.7 LCD Usage\nNow that the LCD is initialized, characters may be written to the LCD by sending their ASCII codes, split up into 4-bit nibbles, to the LCD with the RS control line now set high. This will cause the LCD to write these characters into the DDRAM, where they are directly displayed.\nMany effects may be created by combining the Set DDRAM address and cursor/display shift commands, including left, center, and right-aligned text, scrolling text, or even a small table of sensor readings.\n\n\n\nFigure 5.7: Block diagram of initialization sequence for HD44780U in 4-bit mode (HD44780U Datasheet page 46)\n\n\n\n\n5.2.8 LCD Wait\nThe LCD’s busy flag can be read while it processes commands internally. To handle this, you can implement the lcd_wait function, which repeatedly reads the busy flag by setting R/W to 0 and configuring the data lines as input. When the function should wait in a while loop reading the busy flag until the LCD is again ready to accept commands. Calling lcd_wait should be done before sending any instructions or data to the LCD, to ensure that it is ready to receive data. Alternatively, you can use the sl_sleeptimer_delay_ms function to wait for a duration longer than any command processing requires. While this latter approach is simpler, it is less effective for high-frequency display updates due to the inherent required delay. For this technique, waiting for 2 milliseconds following any command is practical and easy to implement.\n\n\n5.2.9 Exercise: Displaying a centered string\nFor this exercise, write a function that writes a c-string argument centered on the first line of the display. Check that the string passed to the function is no longer than 16 characters. With this condition met, calculate based on the length of the string the DDRAM address offset necessary to center the string.\nFor example, the string EE260 is \\(5\\) characters long. The number of characters that should be blank on the line is \\(16-5=11\\). To left align the text, the necessary offset is obviously \\(0\\). To right align the text, the offset should be \\(11\\), so that the \\(5\\) additional characters are placed directly touching the right side of the display. To center align the text, the remaining blank characters must be divided by 2. An integer division of \\(11/2=5\\) as the decimal is truncated, meaning that the necessary DDRAM offset is \\(5\\), which will leave \\(6\\) characters to the right of the text.\nThe necessary DDRAM offset may then be set using the appropriate LCD command, then the characters of the string transferred to the display.\nAs an extension to this exercise, you may write a function that takes an additional argument to select the type of alignment and display line to place an arbitrary string of text on.",
    "crumbs": [
      "Embedded Systems Design",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Applications of EFR32 I/O**</span>"
    ]
  },
  {
    "objectID": "contents/core/5_efr32applications.html#keypad",
    "href": "contents/core/5_efr32applications.html#keypad",
    "title": "5  Applications of EFR32 I/O",
    "section": "5.3 Keypad",
    "text": "5.3 Keypad\nMany embedded systems with user interfaces are controlled by simple inputs, such as a joystick, multifunctional knobs, or often, a group of buttons. In cases where many buttons are required, such as for numerical or even text input, connecting a single button to its own GPIO pin is inefficient. With a 4x4 grid of buttons requiring 16 pins, an I/O expander or separate microcontroller dedicated to I/O would likely be necessary. However, a clever arrangement of switches in a grid such as this allows for pins to be multiplexed, requiring a minimum of \\(\\sqrt{\\text{\\# of buttons}}\\) pins to read each button. This works by connecting one side of each switch to a common row, and the other side of the switch to a common column. For a 4x4 grid, only 8 pins are necessary to read the entire matrix layout.\n\n5.3.1 Keypad Matrix Wiring\nCommonly available matrix keypads simply implement the row and column switch connections to pushbuttons integrated in the module. Their pinout is often just a connection for each row and column, allowing them to easily be connected to GPIO pins on an MCU, as shown in Figure 5.8.\nThe internal connections of the keypad may be displayed differently depending on preferences for the schematic. However, it is common to see the switches aligned on a 45angle, bridging between their respective row and column common lines, as illustrated in Figure 5.9.\n\n\n\n\n\n\n\nFigure 5.8: Pinout for an off-the-shelf keypad\n\n\n\n\n\n\n\n\n\nFigure 5.9: Schematic diagram of a 4x4 pushbutton switch matrix\n\n\n\n\n5.3.2 Reading Keypad Matrix\nTo read a matrix of switches, one axis should be connected to GPIO outputs. For example, we will connect the rows to output pins, writing all pins high to begin with. The other axis should be connected to internally pulled-down inputs, meaning that when any key is pressed, one of the high rows will be connected to the input, bringing it high. When this is detected, either with polling or an interrupt-based system, the microcontroller may now identify which key has been pressed.\n\n\n5.3.3 Identifying Pressed Key\nOnce the MCU has been alerted that any key has been pressed, it may now scan the switch matrix to determine the specific key. To do this, all rows should be written low, except for the first row. This may be achieved in practice by writing all rows low first, then immediately writing the first row high. The MCU may then check if any key in the first row has been pressed by again reading all of the column inputs. If any of the column inputs are high, the currently checked row and column that is high correspond with the pressed key. Otherwise, the MCU must repeat the process, writing the next row low. In this way, the pressed key can quickly be determined, and other actions can be taken based on it. This process is outlined in Figure 5.10, a flowchart showing the logic necessary for efficient detection of keypresses.\n\n\n\n\n\n\n\nFigure 5.10: Flowchart for detecting any keypress, then identifying the speci ic key\n\n\nA simplified sample implementation of this process is included below. The code implements nested-loop logic to scan a 4x4 matrix keypad using EFR32XG24 Dev Kit GPIO pins. First, the GPIO pins are initialized, with the column input pins (PC04–PC01) are configured as inputs, and the row output pins (PC05, PA07–PA05) are set to push-pull (output) mode. In the main loop, all the row pins are activated by setting them high. Then, if any of the column pins detects a high signal, representing a key press, the program iterates through each row to isolate the pressed key. During this process, all rows are brought low save for the current row of interest, and the program checks each column pin to identify the specific key pressed.\n// column inputs are on PC04-PC01\nconst uint8_t row_ports[] = {2, 0, 0, 0}; // PC05, PA07-PA05 are row outputs\nconst uint8_t row_pins[] = {5, 7, 6, 5};  // PC05, PA07-PA05 are row outputs\n\nint main(void)\n{\n    GPIO-&gt;P[gpioPortC].MODEL |= 0x1111 &lt;&lt; (1 * 4); // input mode\n\n    for (int i = 0; i &lt; 4; i++)\n        GPIO-&gt;P[row_ports[i]].MODEL |= 0x4 &lt;&lt; (row_pins[i] * 4); // output mode\n\n    while (1)\n    {\n        for (int i = 0; i &lt; 4; i++)\n            GPIO-&gt;P_SET[row_ports[i]] = 1 &lt;&lt; row_pins[i]; // set row pins\n\n        if (GPIO-&gt;P[gpioPortC].DIN & 0xF &lt;&lt; 1) // check if any key is pressed\n        {\n            for (int i = 0; i &lt; 4; i++) // loop through all columns\n            {\n                for (int j = 0; j &lt; 4; j++)\n                    GPIO-&gt;P_CLR[row_ports[j]] = 1 &lt;&lt; row_pins[j]; // clear all row pins\n                GPIO-&gt;P_SET[row_ports[i]] = 1 &lt;&lt; row_pins[i];     // set current row pin\n\n                for (int i = 0; i &lt; 4; i++)\n                {\n                    if (GPIO-&gt;P[gpioPortC].DIN &lt;&lt; 1 & 1 &lt;&lt; i) // check if column pin is high\n                    {\n                        // this is the key pressed\n                    }\n                }\n            }\n        }\n    }\n}\n\n\n5.3.4 Power Efficiency\nA key benefit of reading a switch matrix using this technique, especially with the EFR32MG24, which supports GPIO interrupts from all Energy Management levels. This means that the processor may go into its deepest sleep state while still waiting for keypresses from the matrix. This requires interrupt logic, which will be discussed later, but the general implementation is as follows:\nThe GPIO pins for the rows may be set high, and configured to retain their values while in sleep mode. An interrupt to wake the processor from sleep may be enabled on all input pins, meaning that any keypresses will now trigger the interrupt, waking the MCU from sleep. It can now progress directly into the key identification phase, finding the pressed key and performing an action before returning to low-power sleep.\n\n\n5.3.5 Limitations of Switch Matrix\nThere exist a few limitations with this naive technique of reducing GPIO pin usage for a switch matrix, the most significant being the lack of key rollover. This means that the MCU cannot identify multiple keys being pressed, at least not with certainty.\nFinally, if the keypress time is very short, a key pressed and caught by the detection routine may already be released and missed by the identification routine. This can be compounded by switch bouncing because many keyboard matrices lack hardware debouncing, while software debouncing requires keys to be pressed for a longer period of time before the press is registered.\n\n\n5.3.6 Exercise: Propose a solution to the key rollover problem\nModern computer keyboards can detect any of their keys being pressed, as well as any combination of keys being pressed. To do this, they do not even require multiple I/O expanders or additional microcontrollers. Instead, there is electronic hardware integrated into the matrix circuit in series with every switch that ensures the proper key is detected.\nWhat could this hardware be? Explain how it may be used to support multiple simultaneous keypresses.",
    "crumbs": [
      "Embedded Systems Design",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>**Applications of EFR32 I/O**</span>"
    ]
  },
  {
    "objectID": "contents/core/6_gesturerecog_realtime.html",
    "href": "contents/core/6_gesturerecog_realtime.html",
    "title": "6  Real-Time Gesture Recognition",
    "section": "",
    "text": "6.1 Introduction to Edge AI in Embedded Systems\nEdge AI refers to deploying AI models on edge devices, such as microcontrollers, where data is processed locally instead of being sent to a centralized cloud server. This paradigm reduces latency, enhances data privacy, and ensures uninterrupted operation even in environments with limited connectivity.\nAs embedded systems become more advanced, the need for efficient on-device data processing grows. Traditional systems rely heavily on cloud infrastructure, which can introduce latency, data privacy concerns, and increased operational costs. Edge AI addresses these issues by allowing computations to occur on the microcontroller itself, ensuring responsiveness and independence from network stability. With microcontrollers like the EFR32XG24, AI algorithms are executed efficiently despite hardware and memory constraints.",
    "crumbs": [
      "Embedded Machine Learning",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Real-Time Gesture Recognition</span>"
    ]
  },
  {
    "objectID": "contents/core/6_gesturerecog_realtime.html#introduction-to-edge-ai-in-embedded-systems",
    "href": "contents/core/6_gesturerecog_realtime.html#introduction-to-edge-ai-in-embedded-systems",
    "title": "6  Real-Time Gesture Recognition",
    "section": "",
    "text": "// Example: Initialize Edge AI on EFR32XG24\nvoid initEdgeAI() {\n    configureClock();\n    enableAIAccelerator();\n    loadAIModel();\n    initializeSensors();\n}\n\ninitEdgeAI();\n\n6.1.1 Advantages of Edge AI\nEdge AI offers several critical advantages that make it an essential technology for embedded systems:\n\nLow Latency: Immediate processing without reliance on cloud servers.\nImproved Privacy: Sensitive data remains on the device.\nReduced Bandwidth Usage: No need for constant data transmission.\nEnergy Efficiency: Optimized AI models reduce power consumption.\nScalability: Multiple devices can operate independently.\nOffline Operation: Systems continue functioning without an active internet connection.\n\nThese benefits are especially important in applications like gesture recognition, where real-time response is crucial for effective interaction. Devices deployed in remote or resource-limited environments can operate reliably without relying on continuous cloud access.\n// Example: Optimizing AI Model\nvoid optimizeAIModel() {\n    reducePrecision();\n    quantizeWeights();\n    minimizeMemoryFootprint();\n}\n\noptimizeAIModel();\n\n\n6.1.2 Why EFR32XG24 for Edge AI?\nThe EFR32XG24 microcontroller, equipped with an ARM Cortex-M33 core and integrated BLE capabilities, provides an ideal platform for Edge AI applications. Its features include:\n\nSupport for TinyML frameworks.\nDedicated hardware accelerators for AI computations.\nEnergy-efficient architecture for battery-operated devices.\nAdvanced security features for data integrity.\nHigh-speed BLE communication for real-time data transfer.\nIntegrated peripherals for sensor interfacing.\n\n\n// Example: BLE Initialization for Edge AI\nvoid initBLE() {\n    BLE_init();\n    BLE_enable();\n    BLE_setMode(BLE_LOW_POWER);\n}\n\ninitBLE();\nFurthermore, the microcontroller’s native support for TensorFlow Lite for Microcontrollers (TFLM) allows seamless deployment of lightweight AI models. Its power efficiency ensures prolonged operational life.",
    "crumbs": [
      "Embedded Machine Learning",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Real-Time Gesture Recognition</span>"
    ]
  },
  {
    "objectID": "contents/core/6_gesturerecog_realtime.html#gesture-recognition-system-overview",
    "href": "contents/core/6_gesturerecog_realtime.html#gesture-recognition-system-overview",
    "title": "6  Real-Time Gesture Recognition",
    "section": "6.2 Gesture Recognition System Overview",
    "text": "6.2 Gesture Recognition System Overview\nGesture recognition systems are a subset of human-computer interaction technologies that allow users to control and interact with devices using physical gestures. In an embedded context, gesture recognition systems aim to interpret motion patterns captured by sensors like IMUs (Inertial Measurement Units). The EFR32XG24 microcontroller enables real-time gesture recognition while maintaining energy efficiency and responsiveness.\n\n6.2.1 System Components\nA gesture recognition system using the EFR32XG24 microcontroller involves several key components:\n\nSensors: Inertial Measurement Unit (IMU) for capturing motion data.\nAI Model: A lightweight Convolutional Neural Network (CNN) optimized for TinyML.\nData Preprocessing: Noise filtering and segmentation.\nBLE Communication: Real-time data transfer to mobile devices.\nPower Management System: Ensures long battery life.\n\n\n// Example: Read IMU Sensor Data\nfloat readIMU() {\n    float x = IMU_getX();\n    float y = IMU_getY();\n    float z = IMU_getZ();\n    return (x + y + z) / 3;\n}\n\n\n6.2.2 System Workflow\nThe overall workflow of a gesture recognition system includes the following stages:\n\nRaw sensor data is captured using IMU sensors.\nData is preprocessed locally to remove noise.\nPreprocessed data is fed into the AI model.\nThe AI model classifies the gesture.\nResults are sent via BLE to a connected device.\nFeedback is displayed in real-time on a mobile or desktop application.",
    "crumbs": [
      "Embedded Machine Learning",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Real-Time Gesture Recognition</span>"
    ]
  },
  {
    "objectID": "contents/core/6_gesturerecog_realtime.html#ai-model-design-for-gesture-recognition",
    "href": "contents/core/6_gesturerecog_realtime.html#ai-model-design-for-gesture-recognition",
    "title": "6  Real-Time Gesture Recognition",
    "section": "6.3 AI Model Design for Gesture Recognition",
    "text": "6.3 AI Model Design for Gesture Recognition\nThe AI model for gesture recognition is implemented using a TinyML-compatible CNN architecture.\n\n6.3.1 Model Architecture\nThe CNN architecture is carefully designed to balance accuracy, memory consumption, and computational efficiency:\n\nInput Layer: Processes time-series IMU data.\nConvolutional Layers: Extract spatial and temporal patterns.\nDropout Layers: Prevent overfitting.\nFully Connected Layer: Classifies gestures.\nSoftmax Layer: Provides final classification probabilities.\n\n\n// Example: Preprocessing IMU Data\nvoid preprocessIMUData(float* data, int size) {\n    for (int i = 0; i &lt; size; i++) {\n        data[i] = normalize(data[i]);\n    }\n}\n\nTable 6.1: AI Model Layers and Parameters\n\n\nLayer\nType\nOutput Shape\n\n\n\n\nInput\nTime-Series Data\n(128, 3, 1)\n\n\nConv2D\nFeature Extraction\n(64, 128, 3, 8)\n\n\nMaxPooling2D\nDownsampling\n(32, 64, 8)\n\n\nDropout\nRegularization\n-\n\n\nFlatten\nVectorization\n(512)\n\n\nDense\nClassification\n(16)\n\n\nOutput\nSoftmax\n(4)",
    "crumbs": [
      "Embedded Machine Learning",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Real-Time Gesture Recognition</span>"
    ]
  },
  {
    "objectID": "contents/core/6_gesturerecog_realtime.html#sec:methodology",
    "href": "contents/core/6_gesturerecog_realtime.html#sec:methodology",
    "title": "6  Real-Time Gesture Recognition",
    "section": "6.4 Methodology",
    "text": "6.4 Methodology\nThis section outlines the methodology used to design and implement an Edge AI-based gesture recognition system on the EFR32XG24 BLE microcontroller. The methodology consists of four main stages: Data Acquisition, Data Preprocessing, AI Model Development, and System Integration. Each stage is elaborated below.\n\n6.4.1 Data Acquisition\nThe gesture recognition system utilizes an Inertial Measurement Unit (IMU) sensor to capture motion data. The IMU consists of accelerometers, gyroscopes, and magnetometers to measure linear acceleration, angular velocity, and orientation, respectively.\nSensor Configuration:\n\nSensor Type: 6-axis IMU sensor.\nSampling Rate: 50 Hz.\nData Format: Time-series data with X, Y, and Z-axis readings.\n\nThe IMU sensor outputs raw motion data, which is collected in real-time and fed into the microcontroller for preprocessing.\n\n\n6.4.2 Data Preprocessing\nRaw data from the IMU sensor is noisy and requires preprocessing before being fed into the AI model. The preprocessing pipeline includes the following steps:\n\nNoise Filtering: A low-pass filter is applied to remove high-frequency noise.\nNormalization: Sensor readings are normalized to a common scale between 0 and 1.\nSegmentation: The data is divided into fixed-size time windows for analysis.\n\nThe preprocessed data ensures consistency and reduces variability, enabling robust AI model performance.\n\n\n6.4.3 AI Model Development\nThe AI model is implemented using a TinyML-compatible Convolutional Neural Network (CNN). The architecture is optimized for low memory and computational constraints typical of embedded devices.\nModel Architecture:\n\nInput Layer: Accepts preprocessed IMU time-series data.\nConvolutional Layers: Extract spatial and temporal patterns.\nPooling Layers: Reduce dimensionality while retaining critical features.\nDropout Layers: Prevent overfitting during training.\nFully Connected Layers: Map learned features to output classes.\nOutput Layer: Softmax layer providing probabilities for each gesture class.\n\nTraining and Optimization:\n\nFramework: TensorFlow Lite for Microcontrollers (TFLM).\nTraining Dataset: Recorded gesture datasets.\nOptimization Techniques: Weight quantization, reduced precision arithmetic, and model pruning.\n\nThe model was trained offline on a high-performance server and deployed onto the EFR32XG24 microcontroller after optimization.\n\n\n6.4.4 System Integration\nThe final deployment involves integrating the AI model with the EFR32XG24 microcontroller and establishing BLE communication for data transfer and feedback display.\nSystem Workflow:\n\nIMU sensors capture real-time motion data.\nData preprocessing is performed locally on the microcontroller.\nThe preprocessed data is passed to the AI model for gesture classification.\nResults are transmitted via BLE to connected mobile or desktop applications.\nFeedback is displayed in real-time.\n\nPower Management:\n\nAdaptive power management is implemented to minimize battery consumption.\nLow-power BLE mode is enabled for data transmission.\n\n\n\n6.4.5 Evaluation Metrics\nThe system’s performance was evaluated using the following metrics:\n\nAccuracy: Percentage of correct gesture classifications.\nLatency: Time taken for end-to-end gesture recognition.\nPower Consumption: Average energy used per gesture recognition cycle.\n\n\n\n6.4.6 Hardware and Software Tools\n\nHardware: EFR32XG24 BLE microcontroller, IMU sensor module.\nSoftware: TensorFlow Lite for Microcontrollers, Embedded C, BLE SDK.\n\nThe methodology ensures an efficient, real-time, and scalable gesture recognition system optimized for embedded hardware constraints.",
    "crumbs": [
      "Embedded Machine Learning",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Real-Time Gesture Recognition</span>"
    ]
  },
  {
    "objectID": "contents/core/6_gesturerecog_realtime.html#sec:challenges",
    "href": "contents/core/6_gesturerecog_realtime.html#sec:challenges",
    "title": "6  Real-Time Gesture Recognition",
    "section": "6.5 Challenges and Limitations",
    "text": "6.5 Challenges and Limitations\nWhile implementing the Edge AI-based gesture recognition system on the EFR32XG24 microcontroller, several challenges and limitations were encountered. These are discussed below:\n\nHardware Constraints: The limited computational power and memory resources of the microcontroller posed restrictions on the complexity and size of the AI model. Optimizing the AI model for memory efficiency while maintaining accuracy was a significant challenge.\nPower Consumption: Real-time gesture recognition is computationally intensive, and ensuring prolonged battery life for portable devices required careful power management strategies.\nSensor Noise: IMU sensors are susceptible to noise and environmental disturbances, which can introduce inaccuracies in gesture data. Filtering and preprocessing techniques had to be carefully designed to address this issue.\nLatency Constraints: Edge AI systems require minimal latency for real-time performance. Achieving low latency while balancing model accuracy and computational load was challenging.\nBLE Communication Bottlenecks: Real-time data transfer via BLE can be affected by interference, limited bandwidth, and power constraints, impacting system responsiveness.\nScalability:** Scaling the system for multi-gesture recognition or increasing the number of edge devices posed integration challenges due to resource limitations.\nEnvironmental Variability: Gesture recognition accuracy can degrade under varying environmental conditions, such as lighting changes, device orientation, or sudden movements.\n\nAddressing these challenges required a combination of hardware optimization, software fine-tuning, and iterative testing to ensure a balance between performance, accuracy, and efficiency.",
    "crumbs": [
      "Embedded Machine Learning",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Real-Time Gesture Recognition</span>"
    ]
  },
  {
    "objectID": "contents/core/7_gesturerecog_magicwand.html",
    "href": "contents/core/7_gesturerecog_magicwand.html",
    "title": "7  Magic Wand via Gesture Recognition",
    "section": "",
    "text": "7.1 System Overview\nA convolutional neural network (CNN) model was trained in this TinyML project to recognize gestures such as Swipe Up, Swipe Down, and Circle based on the onboard accelerometer data. The detected gestures (Arrow Up, Arrow Down, and Play/Pause) are mapped to media control actions and transmitted over BLE as media key presses and over the UART interface. Figure 7.1 shows an instance of the output.",
    "crumbs": [
      "Embedded Machine Learning",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Magic Wand via Gesture Recognition**</span>"
    ]
  },
  {
    "objectID": "contents/core/7_gesturerecog_magicwand.html#system-overview",
    "href": "contents/core/7_gesturerecog_magicwand.html#system-overview",
    "title": "7  Magic Wand via Gesture Recognition",
    "section": "",
    "text": "Figure 7.1: Sample Data Output via UART Terminal",
    "crumbs": [
      "Embedded Machine Learning",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Magic Wand via Gesture Recognition**</span>"
    ]
  },
  {
    "objectID": "contents/core/7_gesturerecog_magicwand.html#data-collection-and-processing",
    "href": "contents/core/7_gesturerecog_magicwand.html#data-collection-and-processing",
    "title": "7  Magic Wand via Gesture Recognition",
    "section": "7.2 Data Collection and Processing",
    "text": "7.2 Data Collection and Processing\nThe IMU data for this TinyML model was collected at 25Hz with a sequence length of 50 samples to form the input buffer for the CNN. The fastest way to do this is by following the github.com/Ijnaka22len/FastDataCollection4MagicWangProjects repository, which provides a detailed description of IMU data capture for TinyML projects. The captured data is preprocessed and fed into the model as an input image for pattern recognition.\nif __name__ == \"__main__\":\n    delFile(file_path=\"data/complete_data\")\n    delFile(file_path=\"data/test\")\n    delFile(file_path=\"data/train\")\n    delFile(file_path=\"data/valid\")\n    delFile(file_path=\"netmodels/CNN/weights.h5\")\n\n    folders = os.listdir(\"data\")\n    names = [file.split('_')[1].lower() for file in os.listdir(f\"data/{folders[0]}\")]\n    data = []  # pylint: disable=redefined-outer-name\n\n    for idx1, folder in enumerate(folders):\n        files = os.listdir(f\"data/{folder}\")\n        for file in files:\n            name = file.split('_')[1].lower()\n            prepare_original_data(folder, name, data, f\"data/{folder}/{file}\")\n\n    for idx in range(5):\n        prepare_original_data(\"negative\", \"negative%d\" % (idx + 1), data, \"data/negative/negative_%d.txt\" % (idx + 1))\n    \n    generate_negative_data(data)\n    print(\"data_length: \" + str(len(data)))\n\n    if not os.path.exists(\"./data\"):\n        os.makedirs(\"./data\")\n    \n    write_data(data, \"./data/complete_data\")",
    "crumbs": [
      "Embedded Machine Learning",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Magic Wand via Gesture Recognition**</span>"
    ]
  },
  {
    "objectID": "contents/core/7_gesturerecog_magicwand.html#model-architecture-and-deployment",
    "href": "contents/core/7_gesturerecog_magicwand.html#model-architecture-and-deployment",
    "title": "7  Magic Wand via Gesture Recognition",
    "section": "7.3 Model Architecture and Deployment",
    "text": "7.3 Model Architecture and Deployment\nTensorFlow Lite is used to create the CNN model, which takes the processed IMU data as an input image for multiclass classification of the various classes. The AIDrawPen chapter can be reviewed to show how to train a TinyML model for this microcontroller.\n\"\"\"Trains the model.\"\"\"\ncalculate_model_size(model)\nepochs = 50\nbatch_size = 64\nmodel.compile(optimizer=\"adam\",\n              loss=\"sparse_categorical_crossentropy\",\n              metrics=[\"accuracy\"])\nif kind == \"CNN\":\n    train_data = train_data.map(reshape_function)\n    test_data = test_data.map(reshape_function)\n    valid_data = valid_data.map(reshape_function)\n\ntest_labels = np.zeros(test_len)\nidx = 0\nfor data, label in test_data:  # pylint: disable=unused-variable\n    test_labels[idx] = label.numpy()\n    idx += 1\n\ntrain_data = train_data.batch(batch_size).repeat()\nvalid_data = valid_data.batch(batch_size)\ntest_data = test_data.batch(batch_size)\n\nhistory = model.fit(train_data,\n              epochs=epochs,\n              validation_data=valid_data,\n              steps_per_epoch=1000,\n              validation_steps=int((valid_len - 1) / batch_size + 1),\n              callbacks=[tensorboard_callback, early_stop, checkpoint])\n\nloss, acc = model.evaluate(test_data)\npred = np.argmax(model.predict(test_data), axis=1)\nconfusion = tf.math.confusion_matrix(labels=tf.constant(test_labels),\n                                     predictions=tf.constant(pred),\n                                     num_classes=4)",
    "crumbs": [
      "Embedded Machine Learning",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Magic Wand via Gesture Recognition**</span>"
    ]
  },
  {
    "objectID": "contents/core/7_gesturerecog_magicwand.html#firmware-and-model-inference",
    "href": "contents/core/7_gesturerecog_magicwand.html#firmware-and-model-inference",
    "title": "7  Magic Wand via Gesture Recognition",
    "section": "7.4 Firmware and Model Inference",
    "text": "7.4 Firmware and Model Inference\nThe microcontroller firmware contains a code segment to capture the accelerometer data at the predetermined frequency and sampling rate. This data is stored in a buffer and updated every 100ms during gesture detection.\n#include \"accelerometer.h\"\n#include \"config.h\"\n\n#if defined(SL_COMPONENT_CATALOG_PRESENT)\n#include \"sl_component_catalog.h\"\n#endif\n\n#if defined (SL_CATALOG_ICM20689_DRIVER_PRESENT)\n#include \"sl_icm20689_config.h\"\n#define  SL_IMU_INT_PORT SL_ICM20689_INT_PORT\n#define  SL_IMU_INT_PIN  SL_ICM20689_INT_PIN\n#elif defined (SL_CATALOG_ICM20648_DRIVER_PRESENT)\n#include \"sl_icm20648_config.h\"\n#define  SL_IMU_INT_PORT SL_ICM20648_INT_PORT\n#define  SL_IMU_INT_PIN  SL_ICM20648_INT_PIN\n#else\n#error \"No IMU driver defined\"\n#endif\n\n// Accelerometer data from sensor\ntypedef struct imu_data {\n  int16_t x;\n  int16_t y;\n  int16_t z;\n} imu_data_t;\n\nsl_status_t accelerometer_setup(GPIOINT_IrqCallbackPtrExt_t callbackPtr)\n{\n  sl_status_t status = SL_STATUS_OK;\n  int int_id;\n\n  // Initialize accelerometer sensor\n  status = sl_imu_init();\n  if (status != SL_STATUS_OK) {\n    return status;\n  }\n  sl_imu_configure(ACCELEROMETER_FREQ);\n  // Setup interrupt from accelerometer on falling edge\n  GPIO_PinModeSet(SL_IMU_INT_PORT, SL_IMU_INT_PIN, gpioModeInput, 0);\n  int_id = GPIOINT_CallbackRegisterExt(SL_IMU_INT_PIN, callbackPtr, 0);\n  if (int_id != INTERRUPT_UNAVAILABLE) {\n    GPIO_ExtIntConfig(SL_IMU_INT_PORT, SL_IMU_INT_PIN, int_id, false, true, true);\n  } else {\n    status = SL_STATUS_FAIL;\n  }\n  return status;\n}\n\nsl_status_t accelerometer_read(acc_data_t* dst)\n{\n  if (!sl_imu_is_data_ready()) {\n    return SL_STATUS_FAIL;\n  }\n  sl_imu_update();\n  int16_t m[3];\n  sl_imu_get_acceleration(m);\n  CORE_DECLARE_IRQ_STATE;\n  CORE_ENTER_CRITICAL();\n  if (dst != NULL) {\n    dst-&gt;x = m[0];\n    dst-&gt;y = m[1];\n    dst-&gt;z = m[2];\n  }\n  CORE_EXIT_CRITICAL();\n  return SL_STATUS_OK;\n}\nThe quantized CNN model interprets the processed accelerometer data to classify gestures through periodic inference. Results are evaluated against the accepted threshold (#define DETECTION_THRESHOLD 0.9f).\n#include \"sl_tflite_micro_model.h\"\n#include \"sl_tflite_micro_init.h\"\n#include \"sl_sleeptimer.h\"\n#include \"magic_wand.h\"\n#include \"accelerometer.h\"\n#include \"sl_simple_button_instances.h\"\n#include \"math.h\"\n#include \"config.h\"\n// BLE header\n#include \"sl_bluetooth.h\"\n#include \"app_assert.h\"\n#include \"gatt_db.h\"\n#include \"em_common.h\"\n//\nstatic int input_length;\nstatic TfLiteTensor* model_input;\nstatic tflite::MicroInterpreter* interpreter;\nstatic acc_data_t buf[SEQUENCE_LENGTH] = { 0.5f, 0.5f, 0.5f };\nstatic bool infer = false;\nstatic bool read_accel = false;\nstatic int head_ptr = 0;\nstatic int inference_trigger_samples_num = round(INFERENCE_PERIOD_MS / ACCELEROMETER_FREQ);\nstatic acc_data_t prev_data = { 0.5f, 0.5f, 0.5f };\n\nstatic void listen_for_gestures(bool enable)\n{\n  if (enable) {\n    for (uint8_t i = 0; i &lt; SEQUENCE_LENGTH; i++) {\n      acc_data_t _d = { 0.5f, 0.5f, 0.5f };\n      buf[i] = _d;\n    }\n    read_accel = true;\n  } else {\n    read_accel = false;\n    head_ptr = 0;\n  }\n}\n\nvoid sl_button_on_change(const sl_button_t *handle)\n{\n  if (sl_button_get_state(handle) == SL_SIMPLE_BUTTON_PRESSED) {\n    if (&sl_button_btn0 == handle) {\n      listen_for_gestures(true);\n    }\n  } else if (sl_button_get_state(handle) == SL_SIMPLE_BUTTON_RELEASED) {\n    if (&sl_button_btn0 == handle) {\n      listen_for_gestures(false);\n    }\n  }\n}\n\n// Called when the IMU has data available using gpio interrupt.\nstatic void on_data_available(uint8_t int_id, void *ctx)\n{\n  (void) int_id;\n  (void) ctx;\n  acc_data_t data = { 0, 0, 0 };\n  sl_status_t status = accelerometer_read(&data);\n  if (status == SL_STATUS_FAIL || !read_accel) {\n    return;\n  }\n\n  data.x /= 2000;\n  data.y /= 2000;\n  data.z /= 2000;\n\n  acc_data_t delta_data = { 0 };\n  delta_data.x = data.x - prev_data.x;\n  delta_data.y = data.y - prev_data.y;\n  delta_data.z = data.z - prev_data.z;\n\n  delta_data.x = (delta_data.x / 2 + 1) / 2;\n  delta_data.y = (delta_data.y / 2 + 1) / 2;\n  delta_data.z = (delta_data.z / 2 + 1) / 2;\n\n  buf[head_ptr].x = delta_data.x;\n  buf[head_ptr].y = delta_data.y;\n  buf[head_ptr].z = delta_data.z;\n\n  head_ptr++;\n  prev_data.x = data.x;\n  prev_data.y = data.y;\n  prev_data.z = data.z;\n  if (head_ptr &gt;= SEQUENCE_LENGTH) {\n    head_ptr = 0;\n  }\n  if (head_ptr % inference_trigger_samples_num == 0) {\n    infer = true;\n  }\n}",
    "crumbs": [
      "Embedded Machine Learning",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Magic Wand via Gesture Recognition**</span>"
    ]
  },
  {
    "objectID": "contents/core/7_gesturerecog_magicwand.html#data-transfer-and-ble-communication",
    "href": "contents/core/7_gesturerecog_magicwand.html#data-transfer-and-ble-communication",
    "title": "7  Magic Wand via Gesture Recognition",
    "section": "7.5 Data Transfer and BLE Communication",
    "text": "7.5 Data Transfer and BLE Communication\nPredicted data is transferred through BLE using the GATT server as well as logged to the Putty terminal.\nvoid send_gesture_via_ble(uint8_t gesture)\n{\n    printf(\" BLE sent byte: %u\\r\\n\", (unsigned int)gesture);\n    sl_status_t sc;\n    sc = sl_bt_gatt_server_notify_all(gattdb_gesture_data,\n                                        sizeof(gesture),\n                                        &gesture);\n    app_assert_status(sc);\n}",
    "crumbs": [
      "Embedded Machine Learning",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>**Magic Wand via Gesture Recognition**</span>"
    ]
  },
  {
    "objectID": "contents/core/8_anomalydetection_htm.html",
    "href": "contents/core/8_anomalydetection_htm.html",
    "title": "8  IMU Anomaly Detection Using Hierarchical Temporal Memory",
    "section": "",
    "text": "8.1 System Overview\nHierarchical Temporal Memory (HTM) is an algorithm that mimics the brain’s neocortical learning mechanisms and constantly learns time-based patterns in unlabeled data. Anomalies (suspicious data) are flagged when data (IMU data) deviate significantly from learned patterns. In addition to the firmware, a Python script (display_serial.py) is written to monitor patterns and deviations.",
    "crumbs": [
      "Embedded Machine Learning",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>**IMU Anomaly Detection Using Hierarchical Temporal Memory**</span>"
    ]
  },
  {
    "objectID": "contents/core/8_anomalydetection_htm.html#data-collection-and-preprocessing",
    "href": "contents/core/8_anomalydetection_htm.html#data-collection-and-preprocessing",
    "title": "8  IMU Anomaly Detection Using Hierarchical Temporal Memory",
    "section": "8.2 Data Collection and Preprocessing",
    "text": "8.2 Data Collection and Preprocessing\nLike in Chapter 7, the IMU captures accelerometer data in real-time at a frequency of 25Hz. The previous and current readings are processed to normalize motion along the x, y, and z axes into a \\([-1, 1]\\) range as shown below:\nimu_data_normalized.x = imu_data_current.x - imu_data_prev.x;\nimu_data_normalized.y = imu_data_current.y - imu_data_prev.y;\nimu_data_normalized.z = imu_data_current.z - imu_data_prev.z;\n\nimu_data_normalized.x /= 4000;\nimu_data_normalized.y /= 4000;\nimu_data_normalized.z /= 4000;",
    "crumbs": [
      "Embedded Machine Learning",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>**IMU Anomaly Detection Using Hierarchical Temporal Memory**</span>"
    ]
  },
  {
    "objectID": "contents/core/8_anomalydetection_htm.html#htm-model-architecture",
    "href": "contents/core/8_anomalydetection_htm.html#htm-model-architecture",
    "title": "8  IMU Anomaly Detection Using Hierarchical Temporal Memory",
    "section": "8.3 HTM Model Architecture",
    "text": "8.3 HTM Model Architecture\nThe IMU data is encoded into Sparse Distributed Representations (SDRs) to facilitate efficient anomaly detection.\n\n\n\n\n\n\n\nFigure 8.1: Example of IMU Anomaly\n\n\nsl_htm_encoder_simple_number(imu_data_normalized.x, -1.0f, 1.0f, 9, &sdr_x);\nsl_htm_encoder_simple_number(imu_data_normalized.y, -1.0f, 1.0f, 9, &sdr_y);\nsl_htm_encoder_simple_number(imu_data_normalized.z, -1.0f, 1.0f, 9, &sdr_z);\n\nsl_htm_sdr_insert(&input_sdr, &sdr_x, 0, SDR_WIDTH / 3 * 0);\nsl_htm_sdr_insert(&input_sdr, &sdr_y, 0, SDR_WIDTH / 3 * 1);\nsl_htm_sdr_insert(&input_sdr, &sdr_z, 0, SDR_WIDTH / 3 * 2);",
    "crumbs": [
      "Embedded Machine Learning",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>**IMU Anomaly Detection Using Hierarchical Temporal Memory**</span>"
    ]
  },
  {
    "objectID": "contents/core/8_anomalydetection_htm.html#visualization-and-real-time-monitoring",
    "href": "contents/core/8_anomalydetection_htm.html#visualization-and-real-time-monitoring",
    "title": "8  IMU Anomaly Detection Using Hierarchical Temporal Memory",
    "section": "8.4 Visualization and Real-Time Monitoring",
    "text": "8.4 Visualization and Real-Time Monitoring\nThe Python script display_serial.py visualizes anomaly scores in real-time by reading from a serial port connected to the microcontroller at a baudrate=115200. The script maintains a rolling buffer of scores and updates a live plot. This script helps visualize identified anomalies, such as irregular vibrations or sudden movements.\nif line.startswith(\"anom_score\"):\n    line_info = line.split(\":\")\n    anomaly_score = float(line_info[1])\n    buffer.append(anomaly_score)\n    buffer = buffer[1:]\n    axs.plot(buffer, color=\"red\", linewidth=1)\n    fig.tight_layout()\n    fig.canvas.draw()\n    plt.pause(0.001)\n    axs.clear()",
    "crumbs": [
      "Embedded Machine Learning",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>**IMU Anomaly Detection Using Hierarchical Temporal Memory**</span>"
    ]
  },
  {
    "objectID": "contents/core/9_audioml.html",
    "href": "contents/core/9_audioml.html",
    "title": "9  Audio ML for EFR32",
    "section": "",
    "text": "9.1 Overview\nIn the implementation below, the system processes raw audio input and categorizes it as either Yes or No using the trained ML model. The workflow includes three key stages:\nThe explanations and code examples are presented below for clarity. The required concepts are as follows:",
    "crumbs": [
      "Embedded Machine Learning",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>**Audio ML for EFR32**</span>"
    ]
  },
  {
    "objectID": "contents/core/9_audioml.html#overview",
    "href": "contents/core/9_audioml.html#overview",
    "title": "9  Audio ML for EFR32",
    "section": "",
    "text": "Training the ML model using TensorFlow.\nConverting the model to a TensorFlow Lite format.\nDeploying the model on the EFR32 MCU for real-time inference.\n\n\n\nTensorFlow: An open-source framework widely used for developing and deploying machine learning models across platforms, including mobile and embedded systems. TensorFlow provides tools for building, training, and optimizing neural networks, along with TensorFlow Lite for Microcontrollers, which allows ML models to run efficiently on resource-constrained devices.\nAudio Features: Raw audio data, typically represented as waveforms, is transformed into meaningful numerical representations suitable for ML models. Commonly used features include Mel Frequency Cepstral Coefficients (MFCCs), which capture the spectral properties of audio signals, and Spectrograms, which represent the frequency content over time. These features enable neural networks to identify patterns and classify audio inputs accurately.\nEdge ML: Optimization of ML models for performance and memory efficiency on embedded devices.",
    "crumbs": [
      "Embedded Machine Learning",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>**Audio ML for EFR32**</span>"
    ]
  },
  {
    "objectID": "contents/core/9_audioml.html#training-the-model-in-tensorflow",
    "href": "contents/core/9_audioml.html#training-the-model-in-tensorflow",
    "title": "9  Audio ML for EFR32",
    "section": "9.2 Training the Model in TensorFlow",
    "text": "9.2 Training the Model in TensorFlow\n\n9.2.1 Preparing the Data\nLabeled audio clips containing the words Yes and No are required for training a model. A pre-recorded audio dataset, available in WAV format, will be used in this example. These audio files are first loaded, processed to extract MFCC features, and splitted into training and test sets.\nimport tensorflow as tf\nimport librosa\nimport numpy as np\nimport os\n\n# Extract MFCC features from an audio file\ndef extract_mfcc(file_path):\n    y, sr = librosa.load(file_path, sr=None)  # Load the audio file\n    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)  # Extract MFCCs\n    return np.mean(mfcc, axis=1)  # Return the average of the MFCCs\n\n\n# Dataset preparation\ndef prepare_dataset(audio_dir):\n    features = []\n    labels = []\n    for label in ['yes', 'no']:\n        for file in os.listdir(os.path.join(audio_dir, label)):\n            if file.endswith('.wav'):\n                file_path = os.path.join(audio_dir, label, file)\n                mfcc_features = extract_mfcc(file_path)\n                features.append(mfcc_features)\n                labels.append(0 if label == 'no' else 1)  # 0 for \"No\", 1 for \"Yes\"\n    return np.array(features), np.array(labels)\n\nX, y = prepare_dataset('data/audio')\n\n# Splitting dataset into training and testing sets\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\n\n9.2.2 Training the Neural Network Model\nA neural network is defined for binary classification of audio features.\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Dense(64, activation='relu', input_shape=(13,)),  # 13 MFCC features\n    tf.keras.layers.Dense(32, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')  # Sigmoid for binary classification\n\n])\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n\n# Save the trained model\nmodel.save('yes_no_model.h5')",
    "crumbs": [
      "Embedded Machine Learning",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>**Audio ML for EFR32**</span>"
    ]
  },
  {
    "objectID": "contents/core/9_audioml.html#converting-the-model-for-mcu-deployment",
    "href": "contents/core/9_audioml.html#converting-the-model-for-mcu-deployment",
    "title": "9  Audio ML for EFR32",
    "section": "9.3 Converting the Model for MCU Deployment",
    "text": "9.3 Converting the Model for MCU Deployment\nThe trained TensorFlow model is converted into TensorFlow Lite (TFLite) format for efficient deployment on resource-constrained devices.\nmodel = tf.keras.models.load_model('yes_no_model.h5')\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\ntflite_model = converter.convert()\n\n# Save the TensorFlow Lite model\nwith open('yes_no_model.tflite', 'wb') as f:\n    f.write(tflite_model)\nThe conversion produces a ‘.tflite’ file suitable for embedded deployment.",
    "crumbs": [
      "Embedded Machine Learning",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>**Audio ML for EFR32**</span>"
    ]
  },
  {
    "objectID": "contents/core/9_audioml.html#implementing-the-model-on-the-efr32xg24",
    "href": "contents/core/9_audioml.html#implementing-the-model-on-the-efr32xg24",
    "title": "9  Audio ML for EFR32",
    "section": "9.4 Implementing the Model on the EFR32xG24",
    "text": "9.4 Implementing the Model on the EFR32xG24\nThe TensorFlow Lite model is integrated into the EFR32xG24 environment using the appropriate software development kit (SDK) and TensorFlow Lite for Microcontrollers library.\n\n9.4.1 Setting Up the Development Environment\nThe following components are required for setting up the development environment:\n\nEFR32xG24 SDK: The latest version of the Silicon Labs Gecko SDK must be installed.\nTensorFlow Lite for Microcontrollers: This library should be set up within the development environment.\n\n\n\n9.4.2 Loading the Model and Running Inference\nThe TensorFlow Lite model is loaded onto the MCU, input data is prepared, and inference is performed.\n#include \"tensorflow/lite/c/common.h\"\n#include \"tensorflow/lite/micro/micro_interpreter.h\"\n#include \"tensorflow/lite/model.h\"\n#include \"tensorflow/lite/schema/schema_generated.h\"\n#include \"tensorflow/lite/kernels/register.h\"\n\n#define INPUT_SIZE 13\n\n// Declare tensors and interpreter\ntflite::MicroInterpreter* interpreter;\ntflite::Model* model;\ntflite::MicroAllocator* allocator;\n\nfloat input_data[INPUT_SIZE];  // Input data (MFCCs)\nfloat output_data[1];  // Output data (prediction)\n\n\n// Load the TensorFlow Lite model\nvoid LoadModel(const uint8_t* model_data) {\n    model = tflite::GetModel(model_data);\n    tflite::ops::micro::RegisterAllOps();\n    tflite::MicroInterpreter interpreter(model, tensor_arena, kTensorArenaSize, &resolver, &allocator);\n    interpreter.AllocateTensors();\n}\n\n// Perform audio classification\nint ClassifyAudio(float* mfcc_input) {\n    // Copy MFCC data into the input tensor\n    memcpy(interpreter.input(0)-&gt;data.f, mfcc_input, sizeof(float) * INPUT_SIZE);\n    \n    // Perform inference\n    interpreter.Invoke();\n\n    // Get the output prediction\n    float prediction = interpreter.output(0)-&gt;data.f[0];\n\n    // Return classification result: 1 for \"Yes\", 0 for \"No\"\n    return prediction &gt; 0.5 ? 1 : 0;\n\n}\nThe inference results are interpreted as:\n\n1: Detected Yes\n0: Detected No\n\n\n\n9.4.3 Integrating Audio Capture\nAn onboard microphone or an external microphone is often used to interface with the MCU to process real-time audio input. The EFR32xG24 does not include a dedicated audio processing block, requiring integration with a microphone module that outputs either analog signals (such as those from an electret microphone) or digital signals (like those from an I2S microphone). For simplicity, an analog microphone with an ADC on the MCU is employed here, with audio signals sampled, preprocessed, and then classified using the following steps:\n\nConfigure the ADC to sample audio signals.\nCapture the raw samples from the ADC at a suitable rate (e.g., 16 kHz or 8 kHz, depending on requirements).\nPreprocess the audio to extract features such as MFCC (Mel-frequency cepstral coefficients), which are suitable for ML models.\nFeed these features into the model for classification.\n\nHere is an example of how to collect and process audio data using an ADC for feature extraction using the EFR32 SDK.\n#include \"em_device.h\"\n#include \"em_chip.h\"\n#include \"em_adc.h\"\n#include \"em_cmu.h\"\n#include \"em_gpio.h\"\n#include \"em_interrupt.h\"\n\n// ADC buffer for storing captured samples\n#define BUFFER_SIZE 1024\nstatic uint16_t adc_buffer[BUFFER_SIZE];\nstatic volatile uint32_t adc_index = 0;  // Index for storing samples in the buffer\n\n// ADC interrupt handler to collect samples\nvoid ADC0_IRQHandler(void) {\n    // Read the ADC data from the ADC data register\n    adc_buffer[adc_index++] = ADC_DataSingleGet(ADC0);\n\n    // If the buffer is full, stop the ADC conversion\n    if (adc_index &gt;= BUFFER_SIZE) {\n        ADC0-&gt;CMD = ADC_CMD_STOP;\n        adc_index = 0;\n    }\n}\n\n// Initialize the ADC for audio sampling\nvoid ADC_InitAudio(void) {\n    // Enable the clock for ADC and GPIO\n    CMU_ClockEnable(cmuClock_ADC0, true);\n    CMU_ClockEnable(cmuClock_GPIO, true);\n\n    // Configure the GPIO pin for the microphone (assuming it is connected to a pin, e.g., PA0)\n    GPIO_PinModeSet(gpioPortA, 0, gpioModeInput, 0);\n\n    // Configure the ADC to sample at a reasonable rate for audio (e.g., 16 kHz)\n    ADC_Init_TypeDef adcInit = ADC_INIT_DEFAULT;\n    adcInit.prescale = ADC_PrescaleCalc(16000, 0);  // Calculate prescaler for 16kHz sampling rate\n    ADC_Init(ADC0, &adcInit);\n\n    // Configure the ADC single conversion mode\n    ADC_InitSingle_TypeDef adcSingleInit = ADC_INITSINGLE_DEFAULT;\n    adcSingleInit.input = adcSingleInputPin0;  // Set the input channel (e.g., PA0)\n    adcSingleInit.acqTime = adcAcqTime4;       // Set acquisition time\n    ADC_InitSingle(ADC0, &adcSingleInit);\n\n    // Enable the ADC interrupt and start ADC conversions\n    NVIC_EnableIRQ(ADC0_IRQn);\n    ADC0-&gt;CMD = ADC_CMD_START;\n}\n\n\n9.4.4 Audio Preprocessing and Classification\nThe audio data is stored in an array adc_buffer where the ADC samples are placed at regular intervals following these steps:\n\nADC samples the microphone data at a fixed rate.\nThe interrupt service routine (ISR) will be triggered each time the ADC completes a conversion.\nThe ISR stores the data into the adc_buffer.\n\nOnce the raw ADC samples are in the buffer, preprocessing is needed for the ML model. An example is as follows:\n\nConvert the ADC samples to a window of audio (e.g., 25 ms).\nApply a Fourier transform to convert the time-domain signal to the frequency domain.\nExtract MFCC features from the frequency-domain signal.\n\nAn example is provided on how to use the buffer data to classify using a Tensorflow Lite model.\nvoid ProcessAudioAndClassify() {\n    // Preprocess the raw ADC samples (simplified; actual MFCC extraction would be more complex)\n    float mfcc_input[INPUT_SIZE];  // Assumed 13 MFCC features\n    \n    // For simplicity, the ADC data is copied directly into the input array\n    // In a real case, processing is required (e.g., via FFT and MFCC extraction)\n\n    float mfcc_input[INPUT_SIZE];\n    for (int i = 0; i &lt; INPUT_SIZE; i++) {\n        mfcc_input[i] = (float)adc_buffer[i];\n    }\n\n    // Run the model to classify the audio\n    int prediction = ClassifyAudio(mfcc_input);\n    if (prediction == 1) {\n        printf(\"Detected: Yes\\n\");\n    } else {\n        printf(\"Detected: No\\n\");\n    }\n}\nThe main loop manages continuous audio capture and classification.\nint main(void) {\n    CHIP_Init();\n    ADC_InitAudio();\n\n    while (1) {\n        ProcessAudioAndClassify();\n        EMU_EnterEM1();\n    }\n}\n\n\n9.4.5 Considerations for Optimization\n\nADC Resolution: The ADC resolution and sampling rate must align with audio requirements.\nMFCC Extraction: Complex preprocessing, such as Fourier Transform and MFCC extraction, may require optimizations.\nPerformance: Model complexity and sampling rates should be adjusted for available memory and processing capabilities.",
    "crumbs": [
      "Embedded Machine Learning",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>**Audio ML for EFR32**</span>"
    ]
  }
]